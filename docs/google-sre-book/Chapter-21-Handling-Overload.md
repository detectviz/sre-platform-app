# 處理過載 (Handling Overload)

作者：Alejandro Forero Cuervo
編輯：Sarah Chavis

避免過載是負載平衡策略的一個目標。但無論您的負載平衡策略多麼高效，系統的某些部分最終總會變得過載。優雅地處理過載情況是運行可靠服務系統的基礎。

處理過載的一個選項是提供**降級回應 (degraded responses)**：這些回應不如正常回應準確或包含的數據少，但計算起來更容易。例如：

-   與其搜尋整個語料庫來為搜尋查詢提供最佳可用結果，不如只搜尋候選集的一小部分。
-   依賴可能不是最新但使用成本比對著權威儲存體更便宜的本地結果副本。

然而，在極端過載的情況下，服務甚至可能無法計算和提供降級回應。在這一點上，它可能除了提供錯誤之外沒有其他直接的選擇。減輕這種情況的一種方法是在資料中心之間平衡流量，使得沒有資料中心接收超過其處理能力的流量。例如，如果一個資料中心運行 100 個後端任務，每個任務每秒最多能處理 500 個請求，負載平衡演算法將不允許每秒超過 50,000 個查詢被發送到該資料中心。然而，即使是這個限制，在您大規模操作時也可能不足以避免過載。歸根結底，最好是建立能夠優雅處理資源限制的客戶端和後端：在可能的情況下重定向，在必要時提供降級結果，並在所有其他方法都失敗時透明地處理資源錯誤。

## 「每秒查詢數」的陷阱 (The Pitfalls of "Queries per Second")

不同的查詢可能有截然不同的資源需求。查詢的成本可能因任意因素而異，例如發出它們的客戶端中的程式碼（對於有許多不同客戶端的服務）甚至是**一天中的時間**（例如，家庭用戶與工作用戶；或互動式終端用戶流量與批次流量）。

我們以慘痛的教訓學到了這一點：將容量建模為「每秒查詢數」(queries per second) 或使用被認為是其消耗資源代理的請求靜態特徵（例如，「請求正在讀取多少個鍵」）通常會成為一個差勁的指標。即使這些指標在某個時間點表現得足夠好，比例也可能改變。有時變化是漸進的，但有時變化是劇烈的（例如，一個新版本的軟體突然使某些請求的某些功能需要顯著減少的資源）。一個移動的目標對於設計和實施負載平衡來說是一個差勁的指標。

一個更好的解決方案是直接以可用資源來衡量容量。例如，您可能在給定的資料中心為給定的服務總共預留了 500 個 CPU 核心和 1 TB 的記憶體。自然地，直接使用這些數字來建模資料中心的容量效果要好得多。我們經常談論一個請求的**成本 (cost)**，指的是它消耗了多少 CPU 時間的標準化度量（跨越不同的 CPU 架構，並考慮到性能差異）。

在大多數情況下（雖然肯定不是全部），我們發現簡單地使用 CPU 消耗作為配置的信號效果很好，原因如下：

-   在具有**垃圾回收 (garbage collection)** 的平台中，記憶體壓力自然會轉化為增加的 CPU 消耗。
-   在其他平台中，可以以這樣的方式配置剩餘資源，使它們在 CPU 耗盡之前極不可能耗盡。

在非 CPU 資源的超額配置成本過高的情況下，我們在考慮資源消耗時會分別考慮每個系統資源。

# 每客戶限制 (Per-Customer Limits)

處理過載的一個組成部分是決定在**全域過載 (global overload)** 的情況下該怎麼做。在一個完美的世界裡，團隊會與其後端依賴項的所有者仔細協調他們的發布，全域過載永遠不會發生，後端服務總是有足夠的容量來服務他們的客戶。不幸的是，我們並不生活在一個完美的世界。在現實中，全域過載相當頻繁地發生（特別是對於那些往往有許多由許多團隊運行的客戶端的內部服務）。

當全域過載確實發生時，至關重要的是服務只向行為不當的客戶提供錯誤回應，而其他客戶則不受影響。為了實現這一結果，服務所有者根據與客戶協商的使用情況來配置其容量，並根據這些協議定義**每客戶配額 (per-customer quotas)**。

例如，如果一個後端服務在全球（跨越不同資料中心）分配了 10,000 個 CPU，他們的每客戶限制可能看起來像下面這樣：

-   Gmail 被允許每秒消耗高達 4,000 CPU 秒。
-   Calendar 被允許每秒消耗高達 4,000 CPU 秒。
-   Android 被允許每秒消耗高達 3,000 CPU 秒。
-   Google+ 被允許每秒消耗高達 2,000 CPU 秒。
-   所有其他用戶被允許每秒消耗高達 500 CPU 秒。

請注意，這些數字加起來可能超過分配給後端服務的 10,000 個 CPU。服務所有者依賴於這樣一個事實，即他們所有的客戶不太可能同時達到他們的資源限制。

我們從所有後端任務即時匯總全域使用資訊，並使用這些數據向個別後端任務推送有效的限制。更深入地研究實現此邏輯的系統超出了本討論的範圍，但我們已經編寫了重要的程式碼來在我們的後端任務中實現這一點。這個謎題的一個有趣部分是即時計算每個個別請求消耗的資源量——特別是 CPU。對於不實現**每個請求一個執行緒 (thread-per-request)** 模型的伺服器來說，這種計算尤其棘手，在這種模型中，一個執行緒池只是在使用非阻塞 API 的情況下，執行所有傳入請求的不同部分。

# 客戶端節流 (Client-Side Throttling)

當一個客戶超出配額時，後端任務應該快速拒絕請求，期望返回一個「客戶超出配額」的錯誤比實際處理請求並提供正確回應消耗的資源要少得多。然而，這個邏輯並不適用於所有服務。例如，對於需要簡單 RAM 查詢的請求（其中請求/回應協議處理的開銷遠大於產生回應的開銷），拒絕請求幾乎與接受並運行該請求一樣昂貴。即使在拒絕請求可以節省大量資源的情況下，這些請求仍然會消耗一些資源。如果被拒絕的請求數量很大，這些數字會迅速累積。在這種情況下，後端可能會變得過載，儘管其絕大多數 CPU 都花在了僅僅是拒絕請求上！

**客戶端節流 (Client-side throttling)** 解決了這個問題。106 當一個客戶端檢測到其最近的請求中有很大一部分因「超出配額」錯誤而被拒絕時，它開始自我調節並限制其產生的傳出流量。超過上限的請求在本地失敗，甚至不會到達網路。

我們通過一種我們稱之為**適應性節流 (adaptive throttling)** 的技術來實現客戶端節流。具體來說，每個客戶端任務都會保留其歷史記錄中過去兩分鐘的以下資訊：

在正常情況下，這兩個值是相等的。當後端開始拒絕流量時，`accepts` 的數量變得小於 `requests` 的數量。客戶端可以繼續向後端發出請求，直到 `requests` 是 `accepts` 的 K 倍大。一旦達到該截止點，客戶端就開始自我調節，新請求會以在**客戶端請求拒絕機率**中計算出的機率在本地（即在客戶端）被拒絕。

當客戶端本身開始拒絕請求時，`requests` 將繼續超過 `accepts`。雖然這看起來可能違反直覺，因為本地拒絕的請求實際上並未傳播到後端，但這是首選的行為。隨著應用程式嘗試向客戶端發出請求的速率增長（相對於後端接受它們的速率），我們希望增加丟棄新請求的機率。

對於處理一個請求的成本與拒絕該請求的成本非常接近的服務，允許大約一半的後端資源被拒絕的請求消耗是不可接受的。在這種情況下，解決方案很簡單：修改客戶端請求拒絕機率中的 `accepts` 乘數 K（例如，2）。這樣：

-   降低乘數將使適應性節流的行為更具攻擊性
-   增加乘數將使適應性節流的行為不那麼具攻擊性

例如，與其讓客戶端在 `requests = 2 * accepts` 時自我調節，不如讓它在 `requests = 1.1 * accepts` 時自我調節。將修飾符降低到 1.1 意味著後端每接受 10 個請求，只會有一個請求被拒絕。

我們通常更喜歡 2 倍的乘數。通過允許比預期實際允許的更多請求到達後端，我們在後端浪費了更多的資源，但我們也加快了狀態從後端傳播到客戶端的速度。例如，如果後端決定停止拒絕來自客戶端任務的流量，那麼直到所有客戶端任務都檢測到這種狀態變化的延遲會更短。

我們發現適應性節流在實踐中效果很好，導致整體請求速率穩定。即使在大的過載情況下，後端最終每處理一個請求就拒絕一個請求。這種方法的一個巨大優勢是，決策完全由客戶端任務根據本地資訊做出，並且使用相對簡單的實現：沒有額外的依賴關係或延遲懲罰。

一個額外的考慮是，客戶端節流可能不適用於那些只非常零星地向其後端發送請求的客戶端。在這種情況下，每個客戶端對後端狀態的視圖被大大減少，而增加這種可見性的方法往往成本高昂。

# 關鍵性 (Criticality)

**關鍵性 (Criticality)** 是我們發現在全域配額和節流的背景下非常有用的另一個概念。向後端發出的請求與四個可能的關鍵性值之一相關聯，這取決於我們認為該請求有多關鍵：

我們發現四個值足以穩健地建模幾乎所有服務。我們曾多次討論增加更多值的提議，因為這樣可以讓我們更精細地對請求進行分類。然而，定義額外的值將需要更多的資源來操作各種感知關鍵性的系統。

我們已經將關鍵性作為我們 RPC 系統的**一等公民 (first-class notion)**，並且我們努力將其整合到我們的許多控制機制中，以便在應對過載情況時可以考慮到它。例如：

-   當一個客戶用完全域配額時，一個後端任務只有在已經拒絕了所有較低關鍵性的所有請求時，才會拒絕給定關鍵性的請求（事實上，我們系統支持的每客戶限制，如前所述，可以按關鍵性設置）。
-   當一個任務本身過載時，它會更快地拒絕較低關鍵性的請求。
-   適應性節流系統也為每個關鍵性保留單獨的統計數據。

請求的關鍵性與其延遲要求正交，因此也與底層的網路**服務品質 (quality of service, QoS)** 正交。例如，當一個系統在用戶輸入搜尋查詢時顯示搜尋結果或建議時，底層的請求是高度可丟棄的（如果系統過載，不顯示這些結果是可以接受的），但往往有嚴格的延遲要求。

我們還顯著擴展了我們的 RPC 系統以自動傳播關鍵性。如果一個後端收到請求 A，並且作為執行該請求的一部分，向其他後端發出傳出請求 B 和請求 C，那麼請求 B 和請求 C 將預設使用與請求 A 相同的關鍵性。

過去，Google 的許多系統都發展出了自己特有的關鍵性概念，這些概念在服務之間通常不相容。通過將關鍵性作為我們 RPC 系統的一部分進行標準化和傳播，我們現在能夠在特定點上一致地設置關鍵性。這意味著我們可以確信，過載的依賴項將遵守期望的高層級關鍵性來拒絕流量，無論它們在 RPC 堆疊中有多深。因此，我們的做法是盡可能地將關鍵性設置得靠近瀏覽器或行動客戶端——通常是在產生要返回的 HTML 的 HTTP 前端——並且只在堆疊中特定點有意義的特定情況下才覆蓋關鍵性。

# 利用率信號 (Utilization Signals)

我們實現的任務級別過載保護是基於**利用率 (utilization)** 的概念。在許多情況下，利用率只是 CPU 速率的測量（即，當前 CPU 速率除以任務預留的總 CPU），但在某些情況下，我們也考慮了諸如當前正在使用的預留記憶體部分的測量。隨著利用率接近配置的閾值，我們開始根據其關鍵性拒絕請求（較高關鍵性的閾值較高）。

我們使用的利用率信號是基於任務本地的狀態（因為信號的目標是保護任務），並且我們為各種信號提供了實現。最普遍有用的信號是基於進程中的「負載」，這是使用一個我們稱之為**執行器負載平均值 (executor load average)** 的系統來確定的。

為了找到執行器負載平均值，我們計算進程中的活動執行緒數量。在這種情況下，「活動」指的是當前正在運行或準備運行並等待空閒處理器的執行緒。我們用指數衰減來平滑這個值，並在活動執行緒的數量超過任務可用的處理器數量時開始拒絕請求。這意味著一個具有非常大扇出（即，調度一個非常大量的短壽命操作的突發）的傳入請求將導致負載短暫地飆升，但平滑處理將基本上吞噬掉那個尖峰。然而，如果操作不是短壽命的（即，負載增加並在相當長的時間內保持高位），任務將開始拒絕請求。

雖然執行器負載平均值已被證明是一個非常有用的信號，但我們的系統可以插入任何特定後端可能需要的利用率信號。例如，我們可能會使用**記憶體壓力 (memory pressure)**——它指示後端任務中的記憶體使用是否已超出正常操作參數——作為另一個可能的利用率信號。該系統還可以配置為組合多個信號，並拒絕會超過組合（或單獨）目標利用率閾值的請求。

# 處理過載錯誤 (Handling Overload Errors)

除了優雅地處理負載外，我們還深入思考了客戶端在收到與負載相關的錯誤回應時應該如何反應。在過載錯誤的情況下，我們區分兩種可能的情況。

如果資料中心中的一大部分後端任務都過載了，請求不應該被重試，錯誤應該一直冒泡到調用者（例如，向終端用戶返回一個錯誤）。更典型的情況是只有一小部分任務變得過載，在這種情況下，首選的回應是立即重試請求。一般來說，我們的跨資料中心負載平衡系統試圖將流量從客戶端引導到他們最近的可用後端資料中心。在少數情況下，最近的資料中心很遠（例如，一個客戶端可能在不同的大陸有其最近的可用後端），但我們通常設法將客戶端安置在靠近其後端的地方。這樣，重試請求的額外延遲——僅僅幾次網路來回——往往可以忽略不計。

從我們的負載平衡策略的角度來看，請求的重試與新請求是無法區分的。也就是說，我們不使用任何明確的邏輯來確保重試實際上會轉到一個不同的後端任務；我們只是依賴於這樣一個可能的機率，即重試僅僅因為子集中參與的後端數量而落在一個不同的後端任務上。確保所有重試實際上都轉到一個不同的任務，將在我們的 API 中引入比其價值更多的複雜性。

即使一個後端只是輕微過載，如果後端平等而迅速地拒絕重試和新請求，客戶端請求通常會得到更好的服務。這些請求然後可以立即在一個可能有備用資源的不同後端任務上重試。在後端同等對待重試和新請求的後果是，在不同任務中重試請求成為一種有機的負載平衡形式：它將負載重定向到可能更適合這些請求的任務。

## 決定是否重試 (Deciding to Retry)

當一個客戶端收到「任務過載」的錯誤回應時，它需要決定是否重試該請求。我們有一些機制來避免在叢集中的一大部分任務都過載時進行重試。

首先，我們實現了一個**每個請求最多三次嘗試的重試預算 (per-request retry budget)**。如果一個請求已經失敗了三次，我們就讓失敗冒泡到調用者。其理由是，如果一個請求已經三次落在過載的任務上，再次嘗試它不太可能會有幫助，因為整個資料中心可能都過載了。

其次，我們實現了一個**每個客戶端的重試預算 (per-client retry budget)**。每個客戶端都會追蹤對應於重試的請求的比例。只要這個比例低於 10%，請求就會被重試。其理由是，如果只有一小部分任務過載，那麼需要重試的情況就會相對較少。

作為一個具體的例子（最壞情況的場景），讓我們假設一個資料中心正在接受少量請求並拒絕大部分請求。設 X 為根據客戶端邏輯嘗試對資料中心發出的總請求率。由於將會發生重試的次數，請求的數量將顯著增長，到略低於 3X 的地方。儘管我們已經有效地限制了由重試引起的增長，但請求的三倍增長是顯著的，特別是如果拒絕與處理一個請求的成本相當可觀的話。然而，在一般情況下，加上每個客戶端的重試預算（10% 的重試率），將增長減少到僅 1.1 倍——一個顯著的改進。

第三種方法是讓客戶端在請求元數據中包含一個計數器，記錄該請求已經被嘗試了多少次。例如，計數器在第一次嘗試時從 0 開始，每次重試時遞增，直到達到 2，此時每個請求的預算使其停止被重試。後端在最近的歷史記錄中保留這些值的直方圖。當一個後端需要拒絕一個請求時，它會查閱這些直方圖，以確定其他後端任務也過載的可能性。如果這些直方圖顯示有大量的重試（表明其他後端任務可能也過載了），它們會返回一個「過載；不要重試」的錯誤回應，而不是觸發重試的標準「任務過載」錯誤。

圖 21-1 顯示了在各種示例情況下，一個給定的後端任務在一個滑動窗口內收到的每個請求的嘗試次數（對應於 1,000 個初始請求，不計重試）。為簡單起見，忽略了每個客戶端的重試預算（即，這些數字假設重試的唯一限制是每個請求三次嘗試的重試預算），並且子集化可能會在一定程度上改變這些數字。

我們較大的服務往往是深層的系統堆疊，這些系統又可能相互依賴。在這種架構中，請求只應該在拒絕它們的層的正上方一層被重試。當我們決定一個給定的請求無法被服務且不應被重試時，我們使用一個「過載；不要重試」的錯誤，從而避免了**組合重試爆炸 (combinatorial retry explosion)**。

考慮圖 21-2 的例子（在實踐中，我們的堆疊通常要複雜得多）。想像一下，資料庫前端 (DB Frontend) 當前過載並拒絕了一個請求。在這種情況下：

-   後端 B 將根據前述指南重試該請求。
-   然而，一旦後端 B 確定對資料庫前端的請求無法被服務（例如，因為該請求已經被嘗試並拒絕了三次），後端 B 必須向後端 A 返回一個「過載；不要重試」的錯誤或一個降級的回應（假設即使其對資料庫前端的請求失敗，它也能產生一些中等有用的回應）。
-   後端 A 對於它從前端收到的請求有完全相同的選項，並相應地進行處理。

關鍵點是，來自資料庫前端的失敗請求只應該由後端 B，即其正上方的一層來重試。如果多個層次都進行重試，我們將會遇到組合爆炸。

# 連接帶來的負載 (Load from Connections)

與連接相關的負載是最後一個值得一提的因素。我們有時只考慮後端因其收到的請求而直接引起的負載（這是基於每秒查詢數來建模負載的方法的問題之一）。然而，這樣做忽略了維護一個大型連接池的 CPU 和記憶體成本，或連接快速流失的成本。這些問題在小型系統中可以忽略不計，但在運行非常大規模的 RPC 系統時很快就會成為問題。

如前所述，我們的 RPC 協議要求不活動的客戶端執行定期的健康檢查。在一個連接閒置了可配置的時間後，客戶端會丟棄其 TCP 連接並切換到 UDP 進行健康檢查。不幸的是，當您有非常大量的客戶端任務發出非常低的請求率時，這種行為是有問題的：對連接進行健康檢查可能需要比實際服務請求更多的資源。諸如仔細調整連接參數（例如，顯著降低健康檢查的頻率）甚至動態地創建和銷毀連接等方法可以顯著改善這種情況。

處理新連接請求的突發是第二個（但相關的）問題。我們見過這種類型的突發發生在非常大的批次作業中，這些作業一次性創建了非常大量的工人客戶端任務。同時協商和維護過多數量的新連接的需求可以輕易地使一組後端過載。根據我們的經驗，有幾種策略可以幫助減輕這種負載：

-   將負載暴露給跨資料中心的負載平衡演算法（例如，基於叢集的利用率，而不僅僅是請求數量來進行負載平衡）。在這種情況下，來自請求的負載被有效地重新平衡到其他有備用容量的資料中心。
-   強制批次客戶端作業使用一組單獨的批次代理後端任務，這些任務只做一件事，就是將請求轉發到底層後端，並以受控的方式將它們的回應交還給客戶端。因此，您有「批次客戶端 → 批次代理 → 後端」，而不是「批次客戶端 → 後端」。在這種情況下，當非常大的作業開始時，只有批次代理作業會受到影響，從而保護了實際的後端（和更高優先級的客戶端）。實際上，批次代理就像一個保險絲。使用代理的另一個優點是，它通常會減少對後端的連接數量，這可以改善對後端的負載平衡（例如，代理任務可以使用更大的子集，並且可能對後端任務的狀態有更好的視圖）。

# 結論 (Conclusions)

本章和《資料中心的負載平衡》討論了各種技術（確定性子集化、加權循環輪詢、客戶端節流、客戶配額等）如何幫助將負載相對均勻地分佈到資料中心的任務上。然而，這些機制依賴於狀態在分散式系統中的傳播。雖然它們在一般情況下表現得相當好，但實際應用中也出現了少量它們工作不完美的情況。

因此，我們認為確保個別任務受到過載保護至關重要。簡單地說：一個被配置為服務特定流量速率的後端任務，應該繼續以該速率服務流量，而不會對延遲產生任何重大影響，無論有多少超額流量被拋給該任務。作為一個推論，後端任務不應該在負載下崩潰。這些陳述應該在某個流量速率（高於任務配置處理能力的 2 倍甚至 10 倍）下都成立。我們接受，在某個點上系統可能會開始崩潰，而提高這個崩潰發生的閾值變得相對困難。

關鍵是要認真對待這些降級情況。當這些降級情況被忽視時，許多系統將表現出可怕的行為。隨著工作堆積，任務最終耗盡記憶體並崩潰（或最終將幾乎所有的 CPU 都消耗在記憶體顛簸上），延遲會因為流量被丟棄和任務爭奪資源而受到影響。如果不加以制止，系統的一個子集（例如一個單獨的後端任務）的失敗可能會觸發其他系統組件的失敗，可能導致整個系統（或相當大的一個子集）失敗。這種級聯失敗的影響可能如此嚴重，以至於任何大規模運行的系統都必須對其進行保護；請參見《處理級聯失敗》。

一個常見的錯誤是假設一個過載的後端應該關閉並停止接受所有流量。然而，這個假設實際上與穩健負
載平衡的目標背道而馳。我們實際上希望後端繼續盡可能多地接受流量，但只在容量釋放時才接受該負載。一個行為良好的後端，由穩健的負載平衡策略支持，應該只接受它能處理的請求，並優雅地拒絕其餘的請求。

雖然我們有大量的工具來實現良好的負載平衡和過載保護，但沒有萬靈丹：負載平衡通常需要對一個系統及其請求的語義有深入的理解。本章描述的技術隨著 Google 許多系統的需求而發展，並且隨著我們系統性質的持續變化，很可能會繼續發展。

106 例如，參見 Doorman，它提供了一個合作式的分散式客戶端節流系統。