# 監控分散式系統

作者：Rob Ewaschuk 編輯：Betsy Beyer

Google 的 SRE 團隊在建立成功的監控和警報系統方面有一些基本原則和最佳實踐。本章為哪些問題應該通過呼叫來打斷人類，以及如何處理那些不夠嚴重以至於不需要觸發呼叫的問題提供了指導方針。

## 定義

在討論所有與監控相關的主題時，並沒有一個統一共享的詞彙表。即使在 Google 內部，以下術語的用法也各不相同，但這裡列出了最常見的解釋。

- 相互關聯的：例如，一個快取伺服器和一個網頁伺服器
- 共享硬體的不相關服務：例如，一個程式碼儲存庫和一個像 Puppet 或 Chef 這樣的配置系統的主節點

# 為什麼要監控？

監控一個系統有很多原因，包括：

系統監控也有助於為業務分析提供原始輸入，並有助於分析安全漏洞。由於本書專注於 SRE 具有特殊專業知識的工程領域，我們在此不討論監控的這些應用。

監控和警報使系統能夠在它損壞時告訴我們，或者也許告訴我們什麼即將損壞。當系統無法自動修復自身時，我們希望由人類來調查警報，確定是否存在真正的問題，緩解問題，並確定問題的根本原因。除非您正在對系統的非常狹窄範圍的組件進行安全審計，否則您絕不應僅僅因為「某些事情看起來有點奇怪」而觸發警報。

呼叫一個人是對員工時間的相當昂貴的使用。如果員工在工作，呼叫會打斷他們的工作流程。如果員工在家，呼叫會打斷他們的個人時間，甚至可能是他們的睡眠。當呼叫過於頻繁時，員工會產生懷疑、草草瀏覽，甚至忽略傳入的警報，有時甚至會忽略被噪音掩蓋的「真實」呼叫。由於其他噪音干擾了快速診斷和修復，中斷可能會延長。有效的警報系統具有良好的信號和非常低的噪音。

# 為監控設定合理的期望

監控一個複雜的應用程式本身就是一項重大的工程任務。即使有大量現有的用於檢測、收集、顯示和警報的基礎設施，一個擁有 10-12 名成員的 Google SRE 團隊通常也會有一到兩名成員，其主要任務是為他們的服務建立和維護監控系統。隨著我們將通用監控基礎設施通用化和集中化，這個數字隨著時間的推移而減少，但每個 SRE 團隊通常至少有一位「監控人員」。（話雖如此，儘管能夠訪問流量圖儀表板等可能很有趣，SRE 團隊會小心翼翼地避免任何需要有人「盯著螢幕看問題」的情況。）

總的來說，Google 傾向於更簡單、更快速的監控系統，並配備更好的事後分析工具。我們避免使用試圖學習閾值或自動檢測因果關係的「神奇」系統。檢測終端用戶請求率意外變化的規則是一個反例；雖然這些規則仍然盡可能保持簡單，但它們可以非常快速地檢測到一個非常簡單、具體、嚴重的異常。監控資料的其他用途，如容量規劃和流量預測，可以容忍更多的脆弱性，因此也可以容忍更複雜的系統。在非常長的時間範圍（數月或數年）內以低採樣率（數小時或數天）進行的觀測實驗通常也可以容忍更多的脆弱性，因為偶爾的漏採樣不會隱藏長期趨勢。

Google SRE 在複雜的依賴層次結構方面只取得了有限的成功。我們很少使用諸如「如果我知道資料庫很慢，就為資料庫慢發出警報；否則，就為網站普遍緩慢發出警報」之類的規則。依賴依賴關係的規則通常適用於我們系統中非常穩定的部分，例如我們將用戶流量從資料中心排出的系統。例如，「如果一個資料中心被排空，那麼就不要對其延遲發出警報」是一個常見的資料中心警報規則。Google 很少有團隊維護複雜的依賴層次結構，因為我們的基礎設施有著持續不斷的重構速度。

本章中描述的一些想法仍然是理想化的：在不斷變化的系統中，總有空間可以更快地從症狀轉向根本原因。因此，雖然本章為監控系統設定了一些目標，以及一些實現這些目標的方法，但重要的是監控系統——尤其是從生產問題發生，到呼叫人類，再到基本分類和深度除錯的關鍵路徑——應保持簡單，並能被團隊中的每個人理解。

同樣，為了保持低噪音和高信號，您的監控系統中直接發送到呼叫器的元素需要非常簡單和穩健。為人類生成警報的規則應該易於理解，並代表一個明確的故障。

# 症狀與原因

您的監控系統應該解決兩個問題：什麼壞了，為什麼？

「什麼壞了」表示症狀；「為什麼」表示一個（可能是中間的）原因。表 6-1 列出了一些假設的症狀和相應的原因。

| 症狀 | 原因 |
| --- | --- |
| 我正在提供 HTTP 500 或 404 | 資料庫伺服器拒絕連接 |
| 我的回應很慢 | CPU 被一個 bogosort 過載，或者一根乙太網電纜被壓在機架下，表現為部分封包遺失 |
| 南極洲的用戶收不到動畫貓 GIF | 您的內容分發網路討厭科學家和貓科動物，因此將一些客戶端 IP 列入黑名單 |
| 私人內容可被全球讀取 | 一次新的軟體推送導致 ACL 被遺忘，並允許所有請求 |

「什麼」與「為什麼」是撰寫具有最大信號和最小噪音的良好監控的最重要區別之一。

# 黑盒與白盒

我們將大量使用白盒監控與少量但關鍵的黑盒監控相結合。思考黑盒監控與白盒監控最簡單的方法是，黑盒監控是**面向症狀的**，代表**活動的**而非預測的問題：「系統現在沒有正常工作。」白盒監控依賴於檢查系統內部（如日誌或 HTTP 端點）的能力，並配備儀器。因此，白盒監控可以檢測到即將發生的問題、被重試掩蓋的故障等等。

請注意，在一個多層系統中，一個人的症狀是另一個人的原因。例如，假設一個資料庫的性能很慢。對於檢測到它們的資料庫 SRE 來說，緩慢的資料庫讀取是一個**症狀**。然而，對於觀察到網站緩慢的前端 SRE 來說，同樣的緩慢資料庫讀取是一個**原因**。因此，白盒監控有時是面向症狀的，有時是面向原因的，這取決於您的白盒資訊量有多大。

在收集用於除錯的遙測資料時，白盒監控至關重要。如果網頁伺服器在資料庫密集型請求上看起來很慢，您需要知道網頁伺服器感知到的資料庫速度有多快，以及資料庫認為自己有多快。否則，您無法區分一個實際上很慢的資料庫伺服器和您的網頁伺服器與資料庫之間的網路問題。

對於呼叫，黑盒監控的關鍵好處是，它強制要求只有在問題已經發生並導致真實症狀時才去打擾人類。另一方面，對於尚未發生但即將發生的問題，黑盒監控幾乎無用。

# 四個黃金信號

監控的四個黃金信號是**延遲 (latency)**、**流量 (traffic)**、**錯誤 (errors)** 和**飽和度 (saturation)**。如果您只能測量您的面向用戶的系統的四個指標，請專注於這四個。

如果您測量所有四個黃金信號，並在一個信號出現問題（或者在飽和度的情況下，幾乎出現問題）時呼叫一個人，您的服務至少會被監控得相當不錯。

# 關心您的尾部（或，儀器檢測與性能）

從頭開始建立一個監控系統時，很容易會設計一個基於某個數量的**平均值**的系統：平均延遲、節點的平均 CPU 使用率，或資料庫的平均飽和度。後兩種情況帶來的危險是顯而易見的：CPU 和資料庫很容易以非常不平衡的方式被利用。延遲也是如此。如果您運行一個平均延遲為 100 毫秒、每秒 1000 次請求的網頁服務，1% 的請求很可能需要 5 秒鐘。23 如果您的用戶依賴幾個這樣的網頁服務來呈現他們的頁面，一個後端的第 99 個百分位數很容易就變成您前端的**中位數**響應。

區分緩慢的平均值和非常緩慢的請求「尾部」最簡單的方法是收集按延遲分桶的請求計數（適合繪製直方圖），而不是實際的延遲：我服務了多少個介於 0 毫秒和 10 毫秒之間的請求，介於 10 毫秒和 30 毫秒之間的，介於 30 毫秒和 100 毫秒之間的，介於 100 毫秒和 300 毫秒之間的，等等？將直方圖邊界大致按指數分佈（在這種情況下，大約是 3 的倍數）通常是可視化請求分佈的一種簡單方法。

# 為測量選擇適當的解析度

系統的不同方面應該用不同程度的粒度來測量。例如：

- 在一分鐘的時間範圍內觀察 CPU 負載不會揭示即使是持續時間很長的、導致高尾部延遲的尖峰。
- 另一方面，對於一個目標是每年總停機時間不超過 9 小時（99.9% 的年正常運行時間）的網頁服務，每分鐘探測一次或兩次 200（成功）狀態可能過於頻繁。
- 同樣，對於一個目標是 99.9% 可用性的服務，每 1-2 分鐘檢查一次硬碟飽和度可能是不必要的。

在構建測量粒度時要小心。收集每秒的 CPU 負載測量可能會產生有趣的資料，但如此頻繁的測量在收集、儲存和分析上可能非常昂貴。如果您的監控目標要求高解析度但不需要極低的延遲，您可以通過在伺服器上執行內部採樣，然後配置一個外部系統來隨時間或跨伺服器收集和匯總該分佈來降低這些成本。您可以：

1.  每秒記錄當前的 CPU 利用率。
2.  使用 5% 粒度的桶，每秒增加相應的 CPU 利用率桶。
3.  每分鐘匯總這些值。

這種策略讓您能夠觀察到短暫的 CPU 熱點，而不會因為收集和保留而產生非常高的成本。

# 盡可能簡單，但不要更簡單

將所有這些要求疊加在一起，可能會產生一個非常複雜的監控系統——您的系統最終可能會具有以下複雜程度：

- 在不同延遲閾值、不同百分位數、各種不同指標上的警報
- 用於檢測和暴露可能原因的額外程式碼
- 為每個可能的原因關聯的儀表板

潛在複雜性的來源是無窮無盡的。像所有軟體系統一樣，監控也可能變得如此複雜，以至於它變得脆弱、難以更改，並成為一個維護負擔。

因此，在設計您的監控系統時，要著眼於簡單性。在選擇要監控的內容時，請記住以下指導方針：

- 最常捕捉到真實事件的規則應該盡可能簡單、可預測和可靠。
- 很少被執行的資料收集、匯總和警報配置（例如，對於一些 SRE 團隊來說，每季度少於一次）應該被移除。
- 被收集但未在任何預製儀表板中暴露或被任何警報使用的信號，是移除的候選對象。

根據 Google 的經驗，指標的基本收集和匯總，與警報和儀表板相結合，作為一個相對獨立的系統運作良好。（事實上，Google 的監控系統被分解為幾個二進位檔案，但通常人們會了解這些二進位檔案的所有方面。）將監控與檢查複雜系統的其他方面結合起來可能很有誘惑力，例如詳細的系統分析、單一程序除錯、跟踪有關異常或崩潰的詳細資訊、負載測試、日誌收集和分析，或流量檢查。雖然這些主題大多與基本監控有共同之處，但將太多東西混合在一起會導致過於複雜和脆弱的系統。與軟體工程的許多其他方面一樣，維護具有清晰、簡單、鬆散耦合的整合點的獨立系統是一種更好的策略（例如，使用 Web API 以一種可以在長時間內保持不變的格式提取摘要資料）。

# 將這些原則結合起來

本章討論的原則可以被整合為一個關於監控和警報的理念，這個理念在 Google SRE 團隊中得到了廣泛的認可和遵循。雖然這個監控理念有點理想化，但它是撰寫或審查新警報的一個很好的起點，它可以幫助您的組織提出正確的問題，無論您的組織規模大小或您的服務或系統的複雜性如何。

在創建監控和警報規則時，問以下問題可以幫助您避免誤報和呼叫器疲勞：24

- 這條規則是否檢測到一個原本未被檢測到的、緊急的、可操作的、並且正在或即將對用戶可見的情況？25
- 我是否能夠在知道這個警報是良性的情況下忽略它？我何時以及為何能夠忽略這個警報，以及我如何避免這種情況？
- 這個警報是否明確表示用戶正在受到負面影響？是否存在可檢測到的、用戶未受負面影響的情況，例如流量排空或測試部署，應該被過濾掉？
- 我能否對這個警報採取行動？這個行動是緊急的，還是可以等到早上？這個行動能否被安全地自動化？這個行動是長期修復，還是只是短期解決方案？
- 是否有其他人也因為這個問題而被呼叫，從而導致至少有一個呼叫是不必要的？

這些問題反映了一個關於呼叫和呼叫器的基本理念：

- 每次呼叫器響起時，我都應該能夠以一種緊迫感做出反應。我每天只能以緊迫感做出幾次反應，然後就會感到疲勞。
- 每個呼叫都應該是可操作的。
- 每個呼叫響應都應該需要智慧。如果一個呼叫僅僅需要一個機器人式的響應，它就不應該是一個呼叫。
- 呼叫應該是關於一個新穎的問題或一個以前從未見過的事件。

這樣的觀點消除了某些區別：如果一個呼叫滿足了上述四點，那麼無論這個呼叫是由白盒還是黑盒監控觸發的，都無關緊要。這個觀點也放大了某些區別：花費更多精力來捕捉症狀比捕捉原因要好得多；至於原因，只擔心非常明確、非常迫在眉睫的原因。

# 長期監控

在現代生產系統中，監控系統跟踪一個不斷演變的系統，其軟體架構、負載特性和性能目標都在變化。一個目前異常罕見且難以自動化的警報可能會變得頻繁，甚至可能需要一個臨時拼湊的腳本來解決它。在這一點上，應該有人找到並消除問題的根本原因；如果無法解決，警報響應就應該被完全自動化。

重要的是，關於監控的決策應著眼於長期目標。今天發生的每一次呼叫都會分散一個人力去改進明天的系統，因此，為了系統的長期前景，通常有理由接受短期的可用性或性能損失。讓我們來看兩個說明這種權衡的案例研究。

## Bigtable SRE：一個過度警報的故事

Google 的內部基礎設施通常是根據服務水準目標 (SLO；請參閱「服務水準目標」) 來提供和衡量的。許多年前，Bigtable 服務的 SLO 是基於一個合成的、行為良好的客戶端的平均性能。由於 Bigtable 和儲存堆疊較低層的問題，平均性能是由一個「大」尾部驅動的：最差的 5% 的請求通常比其餘的慢得多。

當 SLO 接近時，會觸發電子郵件警報，當 SLO 超過時，會觸發呼叫警報。這兩種類型的警報都大量觸發，消耗了不可接受的工程時間：團隊花費大量時間來分類警報，以找到少數真正可操作的警報，我們經常錯過真正影響用戶的問題，因為這樣做的問題很少。許多呼叫都是非緊急的，是由於基礎設施中眾所周知的問題引起的，並且要么有固定的響應，要么沒有響應。

為了糾正這種情況，團隊採用了三管齊下的方法：在努力提高 Bigtable 性能的同時，我們也暫時調低了我們的 SLO 目標，使用第 75 個百分位數的請求延遲。我們還禁用了電子郵件警報，因為它們太多了，花時間診斷它們是不可行的。

這種策略給了我們足夠的喘息空間，讓我們能夠真正解決 Bigtable 和儲存堆疊較低層的長期問題，而不是不斷地解決戰術問題。值班工程師在不被無時無刻的呼叫打擾的情況下，可以真正完成工作。最終，暫時放鬆我們的警報使我們能夠更快地朝著更好的服務邁進。

## Gmail：來自人類的可預測、可編寫腳本的響應

在 Gmail 的早期，該服務是建立在一個經過改造的分散式進程管理系統 Workqueue 上的，該系統最初是為批次處理搜尋索引的片段而創建的。Workqueue 被「改造」以適應長期運行的進程，並隨後應用於 Gmail，但排程器中相對不透明的程式碼庫中的某些錯誤被證明很難解決。

當時，Gmail 的監控結構是，當單個任務被 Workqueue「取消排程」時，會觸發警報。這種設置並不理想，因為即使在那個時候，Gmail 也有成千上萬的任務，每個任務都代表我們用戶的百分之幾。我們非常關心為 Gmail 用戶提供良好的用戶體驗，但這樣的警報設置是無法維護的。

為了解決這個問題，Gmail SRE 建立了一個工具，幫助以恰到好處的方式「戳一下」排程器，以最大限度地減少對用戶的影響。團隊曾多次討論是否應該簡單地自動化從檢測問題到輕推重新排程器的整個循環，直到實現更好的長期解決方案，但有些人擔心這種變通辦法會延遲真正的修復。

這種緊張關係在團隊中很常見，通常反映了對團隊自律的潛在不信任：雖然一些團隊成員希望實施一個「駭客」來為適當的修復爭取時間，但其他人擔心駭客會被遺忘，或者適當的修復會被無限期地降低優先級。這種擔憂是可信的，因為通過修補問題而不是進行真正的修復，很容易建立起無法維護的技術債務層。管理者和技術領導者在實施真正的、長期的修復中扮演著關鍵角色，他們支持並優先考慮潛在耗時的長期修復，即使最初的呼叫「痛苦」消退了。

具有固定、演算法響應的呼叫應該是一個危險信號。您的團隊不願意自動化此類呼叫意味著團隊對他們能夠清理技術債務缺乏信心。這是一個值得升級的主要問題。

## 長遠來看

一個共同的主題連接了前面 Bigtable 和 Gmail 的例子：短期可用性與長期可用性之間的緊張關係。通常，純粹的努力可以幫助一個搖搖欲墜的系統實現高可用性，但這條路通常是短暫的，充滿了倦怠和對少數英雄團隊成員的依賴。採取受控的、短期的可用性下降通常是一個痛苦但具有戰略意義的權衡，以換取系統的長期穩定性。重要的是不要將每一次呼叫都視為一個孤立的事件，而是要考慮整體的呼叫水平是否會導向一個健康的、適當可用的系統，以及一個健康的、可行的團隊和長遠的前景。我們在與管理層的季度報告中審查關於呼叫頻率的統計資料（通常表示為每個班次的事件數，其中一個事件可能由幾個相關的呼叫組成），確保決策者了解其團隊的呼叫器負載和整體健康狀況。

# 結論

一個健康的監控和警報管線是簡單且易於推理的。它主要關注用於呼叫的症狀，保留面向原因的啟發式方法作為除錯問題的輔助手段。監控症狀在您的堆疊中越「往上」監控就越容易，儘管對資料庫等子系統的飽和度和性能的監控通常必須直接在子系統本身上執行。電子郵件警報的價值非常有限，並且很容易被噪音淹沒；相反，您應該偏好一個儀表板，該儀表板監控所有正在進行的次要關鍵問題，以獲取通常最終會出現在電子郵件警報中的那類資訊。儀表板也可以與日誌配對，以便分析歷史相關性。

從長遠來看，實現一個成功的在線輪班和產品包括選擇對症狀或即將發生的真正問題發出警報，將您的目標調整為實際可實現的目標，並確保您的監控支持快速診斷。

22 有時被稱為「警報垃圾郵件」，因為它們很少被閱讀或採取行動。

23 如果您 1% 的請求是平均值的 50 倍，這意味著您其餘的請求大約是平均值的兩倍快。但是，如果您不測量您的分佈，那麼您的大多數請求都接近平均值的想法只是痴人說夢。

24 請參閱「將心臟警報管理技術應用於您的值班 [Hol14]」，了解另一種情況下的警報疲勞範例。

25 零冗餘 (N + 0) 情況算作即將發生，服務的「幾乎已滿」部分也是如此！有關冗餘概念的更多詳細資訊，請參閱 https://en.wikipedia.org/wiki/N%2B1_redundancy。