# Google 自動化的演進

作者：Niall Murphy 與 John Looney 和 Michael Kacirek  編輯：Betsy Beyer

> 除了黑魔法，就只有自動化和機械化了。
>
> Federico García Lorca (1898–1936)，西班牙詩人與劇作家

對於 SRE 來說，自動化是力量的倍增器，而非萬靈丹。當然，僅僅倍增力量並不能自然地改變力量施加的準確性：草率地進行自動化可能會製造出和它解決的問題一樣多的問題。因此，雖然我們相信基於軟體的自動化在大多數情況下優於手動操作，但比這兩種選擇都更好的是一個更高層次的系統設計，它既不需要手動操作也不需要外部自動化——一個**自主 (autonomous)** 系統。或者換句話說，自動化的價值既來自於它所做的事情，也來自於其明智的應用。我們將討論自動化的價值以及我們的態度如何隨著時間的推移而演變。

## 自動化的價值

自動化的價值究竟是什麼？26

### 一致性

雖然規模是自動化的一個明顯動機，但使用它還有許多其他原因。以大學計算系統為例，許多系統工程人員在那裡開始他們的職業生涯。那種背景的系統管理員通常負責運行一系列機器或某些軟體，並習慣於手動執行各種操作來履行職責。一個常見的例子是創建用戶帳戶；其他例子包括純粹的操作性職責，如確保備份發生、管理伺服器故障轉移，以及小的資料操作，如更改上游 DNS 伺服器的 `resolv.conf`、DNS 伺服器區域資料等類似活動。然而，最終，這種手動任務的普遍存在對於組織和以這種方式維護系統的人來說都是不令人滿意的。首先，由一個人或多個人執行數百次的任何操作，每次的執行方式都不會相同：即使有最好的意願，我們中很少有人能像機器一樣始終如一。這種不可避免的缺乏一致性會導致錯誤、疏忽、資料品質問題，以及，是的，可靠性問題。在這個領域——執行範圍明確、已知的程序——一致性的價值在許多方面是自動化的主要價值。

### 一個平台

自動化不僅僅提供一致性。設計和執行得當，自動化系統還提供了一個可以擴展、應用於更多系統，甚至可能分拆出來盈利的**平台**。27（另一種選擇，沒有自動化，既不具成本效益也不可擴展：它反而是對系統運營徵收的一種稅。）

一個平台也**集中了錯誤**。換句話說，程式碼中的一個錯誤將在那裡被一次性永久修復，不像前面討論過的一大群人執行相同的程序。一個平台可以更容易地擴展以執行額外的任務，比指示人類去執行它們（有時甚至意識到必須去做）要容易得多。根據任務的性質，它可以持續運行，或者比人類能適當完成任務的頻率高得多，或者在對人類不方便的時間運行。此外，一個平台可以匯出關於其性能的指標，或者以其他方式讓您發現以前不知道的關於您流程的細節，因為這些細節在平台的上下文中更容易測量。

### 更快的修復

對於使用自動化來解決系統中常見故障的系統（SRE 創建的自動化中的常見情況），還有一個額外的好處。如果自動化運行得足夠規律和成功，結果是這些常見故障的**平均修復時間 (mean time to repair, MTTR)** 減少。然後您可以將時間花在其他任務上，從而實現更高的開發速度，因為您不必花時間去預防問題或（更常見的是）在其後進行清理。正如業界所熟知，在產品生命週期中發現問題越晚，修復的成本就越高；請參閱「可靠性測試」。通常，在實際生產中發生的問題在時間和金錢上都是最昂貴的，這意味著一個在問題一出現就尋找問題的自動化系統，在系統足夠大的情況下，很有可能降低系統的總成本。

### 更快的行動

在 SRE 自動化傾向於部署的基礎設施情況下，人類通常不像機器那樣反應迅速。在大多數常見情況下，例如，對於特定應用程式可以很好地定義故障轉移或流量切換，實際上要求一個人斷斷續續地按下一個名為「允許系統繼續運行」的按鈕是沒有意義的。（是的，有時自動程序確實會使糟糕的情況變得更糟，但這就是為什麼此類程序應該在定義明確的領域內進行範圍界定的原因。）Google 有大量的自動化；在許多情況下，我們支持的服務如果沒有這種自動化就無法長期生存，因為它們很久以前就跨過了可管理的體力勞動的門檻。

### 節省時間

最後，節省時間是自動化經常被引用的理由。儘管人們比其他理由更多地引用這個理由來進行自動化，但在許多方面，其好處通常不那麼容易立即計算出來。工程師們常常在某個特定的自動化或程式碼是否值得編寫上猶豫不決，權衡的是不需要手動執行任務所節省的精力與編寫它所需的精力。28 人們很容易忽略這樣一個事實：一旦你將某個任務封裝在自動化中，**任何人**都可以執行該任務。因此，時間的節省適用於所有可能使用該自動化的人。將操作員與操作解耦是非常強大的。

Joseph Bironas，一位曾一度領導 Google 資料中心啟用工作的 SRE，有力地論證道：

> 「如果我們設計的流程和解決方案是不可自動化的，我們就得繼續配備人力來維護系統。如果我們必須配備人力來做這項工作，我們就是在用人類的血、汗和淚來餵養機器。想像一下《駭客任務》，只是特效少了點，系統管理員更不爽了。」

# 對 Google SRE 的價值

所有這些好處和權衡對我們來說和其他人一樣適用，而且 Google 確實強烈傾向於自動化。我們對自動化的偏好部分源於我們特定的業務挑戰：我們負責的產品和服務規模遍及全球，我們通常沒有時間像其他組織那樣進行那種對機器或服務的「手把手」操作。29 對於真正大型的服務，一致性、速度和可靠性等因素在大多數關於自動化權衡的討論中佔據主導地位。

支持自動化的另一個論點，尤其是在 Google 的情況下，是我們複雜但出奇地統一的生產環境，如「從 SRE 的角度看 Google 的生產環境」中所述。雖然其他組織可能有一台沒有現成 API 的重要設備、沒有原始碼的軟體，或其他妨礙對生產運營完全控制的障礙，但 Google 通常會避免這種情況。當供應商沒有提供 API 時，我們為系統建立了 API。儘管在短期內為特定任務購買軟體會便宜得多，但我們選擇編寫自己的解決方案，因為這樣做產生的 API 具有帶來更大長期利益的潛力。我們花了很多時間來克服自動化系統管理的障礙，然後堅定地開發了自動化系統管理本身。鑑於 Google 管理其原始碼的方式 [Pot16]，SRE 接觸的幾乎所有系統的程式碼都可用，這也意味著我們「在生產中擁有產品」的使命要容易得多，因為我們控制了整個技術堆疊。

當然，儘管 Google 在意識形態上傾向於在可能的情況下使用機器來管理機器，但現實需要對我們的方法進行一些修改。並非每個系統的每個組件都適合自動化，也並非每個人在特定時間都有能力或意願去開發自動化。一些必要的系統最初是作為快速原型開始的，並非為持久或與自動化介面而設計。前面的段落陳述了我們立場的極端觀點，但這是在 Google 的背景下我們已廣泛成功付諸實踐的觀點。總的來說，我們選擇在可能的地方創建平台，或者將自己定位於能夠隨著時間的推移創建平台。我們認為這種基於平台的方法對於可管理性和可擴展性是必要的。

# 自動化的使用案例

在業界，「自動化」這個詞通常用來指編寫程式碼來解決各種各樣的問題，儘管編寫這些程式碼的動機和解決方案本身通常大相逕庭。更廣泛地說，在這種觀點下，自動化是「元軟體」——作用於軟體的軟體。

正如我們前面所暗示的，自動化有許多使用案例。以下是一個非詳盡的例子列表：

- 用戶帳戶創建
- 服務的叢集啟用和停用
- 軟體或硬體安裝準備和退役
- 新軟體版本的推出
- 執行期配置變更
- 執行期配置變更的一個特例：對您依賴項的變更

這個列表可以無限地繼續下去。

## Google SRE 的自動化使用案例

在 Google，我們擁有剛才列出的所有使用案例，甚至更多。

然而，在 Google SRE 內部，我們的主要親和力通常是運行基礎設施，而不是管理流經該基礎設施的資料品質。這條界線並不完全清晰——例如，如果一次推送後一半的資料集消失了，我們會非常關心，因此我們會對這種粗略的差異發出警報，但我們很少會編寫相當於更改系統上任意帳戶子集屬性的程式碼。因此，我們自動化的背景通常是管理系統生命週期的自動化，而不是其資料：例如，在新叢集中部署服務。

就此而言，SRE 的自動化努力與許多其他人及組織所做的相去不遠，只是我們使用不同的工具來管理它，並且有不同的重點（我們將會討論）。

廣泛可用的工具，如 Puppet、Chef、cfengine，甚至 Perl，都提供了自動化特定任務的方法，它們的主要區別在於為幫助自動化行為而提供的組件的抽象層級。像 Perl 這樣的完整語言提供了 POSIX 層級的 affordances，理論上可以在系統可訪問的 API 之間提供幾乎無限的自動化範圍，30 而 Chef 和 Puppet 則提供了開箱即用的抽象，可以用來操作服務或其他更高層級的實體。這裡的權衡是經典的：更高層級的抽象更容易管理和推理，但當你遇到「有漏洞的抽象」時，你會系統性地、重複地、並且可能不一致地失敗。例如，我們通常假設將一個新的二進位檔案推送到一個叢集是原子性的；該叢集最終要麼是舊版本，要麼是新版本。然而，現實世界的行為更為複雜：該叢集的網路可能會中途失敗；機器可能會失敗；與叢集管理層的通信可能會失敗，使系統處於不一致的狀態；根據情況，新的二進位檔案可能已被暫存但未被推送，或被推送但未被重啟，或被重啟但無法驗證。很少有抽象能夠成功地模擬這些類型的結果，大多數通常最終會停止自己並呼叫干預。真正糟糕的自動化系統甚至連這都做不到。

SRE 在自動化領域有許多理念和產品，其中一些看起來更像是通用的推出工具，沒有特別詳細地建模更高層級的實體，而另一些則更像是用於在非常抽象的層級上描述服務部署（等等）的語言。在後者方面所做的工作往往比前者更具可重用性，更像一個通用平台，但我們生產環境的複雜性有時意味著前者的方法是最直接可行的選擇。

## 自動化類別的層次結構

儘管所有這些自動化步驟都很有價值，而且自動化平台本身也很有價值，但在理想世界中，我們並不需要外部化的自動化。事實上，與其擁有一個必須有外部**膠水邏輯 (glue logic)** 的系統，不如擁有一個**完全不需要膠水邏輯**的系統，這不僅僅是因為內部化更有效率（儘管這種效率很有用），而是因為它從一開始就被設計為不需要膠水邏輯。要做到這一點，需要將膠水邏輯的使用案例——通常是系統的「一階」操作，如添加帳戶或執行系統啟用——並找到一種直接在應用程式內部處理這些使用案例的方法。

舉一個更詳細的例子，Google 的大多數啟用自動化都存在問題，因為它最終與核心系統分開維護，因此會遭受「位元腐爛 (bit rot)」，即在底層系統更改時它不會更改。儘管有最好的意圖，試圖更緊密地耦合兩者（啟用自動化和核心系統）通常會因為優先級不一致而失敗，因為產品開發人員會（不無道理地）抵制對每個變更都要求進行測試部署。其次，至關重要但僅在不頻繁的間隔執行，因此難以測試的自動化，通常特別脆弱，因為其反饋週期延長。叢集故障轉移是這種不頻繁執行的自動化的一個典型例子：故障轉移可能每幾個月才發生一次，或者頻率低到足以在實例之間引入不一致性。自動化的演進遵循一條路徑：

SRE 討厭手動操作，所以我們顯然會嘗試創建不需要它們的系統。然而，有時手動操作是不可避免的。

此外，還有一種自動化的子類別，它應用的變更不是跨越特定系統相關配置的領域，而是跨越整個生產環境。在像 Google 這樣高度集中化的專有生產環境中，有大量的變更具有非服務特定的範圍——例如，更改上游 Chubby 伺服器、對 Bigtable 客戶端庫的標誌更改以使存取更可靠等等——但這些變更仍然需要被安全地管理，並在必要時回滾。超過一定的變更量後，手動完成生產範圍內的變更是不可行的，而在那之前的某個時候，對於一個大部分變更是微不足道或通過基本的重新啟動和檢查策略成功完成的流程，進行手動監督是一種浪費。

讓我們用內部案例研究來詳細說明前面的一些觀點。第一個案例研究是關於我們如何通過一些勤奮、有遠見的工作，成功地實現了 SRE 自稱的涅槃：將自己自動化出局。

# 將自己自動化出局：自動化所有事情！

很長一段時間裡，Google 的廣告產品將其資料儲存在 MySQL 資料庫中。由於廣告資料顯然具有高可靠性要求，一個 SRE 團隊負責照管該基礎設施。從 2005 年到 2008 年，廣告資料庫大多在我們認為是成熟和受管理的狀態下運行。例如，我們已經將標準副本替換的最糟糕但非全部的常規工作自動化了。我們相信廣告資料庫管理良好，並且我們已經在優化和擴展方面收穫了大部分低垂的果實。然而，隨著日常運營變得舒適，團隊成員開始著眼於下一層次的系統開發：將 MySQL 遷移到 Google 的叢集排程系統 Borg 上。

我們希望這次遷移能帶來兩個主要好處：

- **完全消除機器/副本維護**：Borg 將自動處理新任務和損壞任務的設定/重啟。
- **能夠在同一台物理機器上打包多個 MySQL 實例**：Borg 將通過容器實現更高效的機器資源利用。

2008 年底，我們成功地在 Borg 上部署了一個概念驗證的 MySQL 實例。不幸的是，這伴隨著一個重大的新困難。Borg 的一個核心操作特性是其任務會自動移動。任務在 Borg 內移動的頻率通常為每週一次或兩次。這個頻率對於我們的資料庫副本來說是可以容忍的，但對於我們的主節點來說是不可接受的。

當時，主節點故障轉移的過程每個實例需要 30-90 分鐘。僅僅因為我們在共享機器上運行，並且會因核心升級而重啟，再加上正常的機器故障率，我們每週都必須預期會發生一些其他無關的故障轉移。這個因素，再加上我們系統所在的碎片數量，意味著：

- **手動故障轉移**將消耗大量的人力時間，並且最多只能為我們提供 99% 的正常運行時間，這低於產品的實際業務需求。
- 為了滿足我們的**錯誤預算**，每次故障轉移的停機時間必須少於 30 秒。
- 沒有辦法優化一個依賴於人的程序，使其停機時間短於 30 秒。

因此，我們唯一的選擇是**自動化故障轉移**。實際上，我們需要自動化的不僅僅是故障轉移。

2009 年，廣告 SRE 完成了我們的自動故障轉移守護進程，我們稱之為「決策者 (Decider)」。決策者可以在 95% 的時間內，在 30 秒內完成計劃性和非計劃性 MySQL 故障轉移。隨著決策者的創建，Borg 上的 MySQL (MoB) 終於成為現實。我們從優化基礎設施以避免故障轉移，畢業到擁抱「失敗是不可避免的」這一理念，並因此通過自動化來優化快速恢復。

雖然自動化讓我們在一個每週被迫重啟多達兩次的世界中實現了高可用的 MySQL，但它也帶來了自己的成本。我們所有的應用程式都必須進行更改，以包含比以前多得多的故障處理邏輯。鑑於 MySQL 開發界的常態是假設 MySQL 實例將是堆疊中最穩定的組件，這種轉換意味著需要客製化像 JDBC 這樣的軟體，以使其更能容忍我們這個容易出錯的環境。然而，遷移到帶有決策者的 MoB 所帶來的好處遠遠超過這些成本。一旦上了 MoB，我們團隊花在單調乏味的操作任務上的時間減少了 95%。我們的故障轉移是自動化的，因此單個資料庫任務的中斷不再需要呼叫人類。

這種新自動化的主要結果是，我們有了更多的空閒時間來改善基礎設施的其他部分。這種改進產生了連鎖效應：我們節省的時間越多，我們就能花更多的時間來優化和自動化其他乏味的工作。最終，我們能夠自動化模式更改，使得廣告資料庫的總運營維護成本下降了近 95%。有人可能會說，我們成功地將自己從這份工作中自動化出局了。我們領域的硬體方面也看到了改進。遷移到 MoB 釋放了大量資源，因為我們可以在同一台機器上排程多個 MySQL 實例，這提高了我們硬體的利用率。總的來說，我們能夠釋放出約 60% 的硬體。我們的團隊現在硬體和工程資源都非常充裕。

這個例子展示了多走一里路來提供一個平台，而不是僅僅替換現有的手動程序的智慧。下一個例子來自叢集基礎設施團隊，它說明了在自動化所有事情的路上你可能會遇到的一些更困難的權衡。

# 撫平傷痛：將自動化應用於叢集啟用

十年前，叢集基礎設施 SRE 團隊似乎每隔幾個月就會有新員工加入。事實證明，這大約也是我們啟用一個新叢集的頻率。由於在新叢集中啟用一個服務可以讓新員工接觸到服務的內部，這個任務似乎是一個自然且有用的培訓工具。

讓一個叢集準備好使用的步驟大致如下：

1.  為資料中心建築配置電力和冷卻。
2.  安裝和配置核心交換器以及與骨幹網路的連接。
3.  安裝最初的幾架伺服器。
4.  配置基本服務，如 DNS 和安裝程式，然後配置鎖服務、儲存和計算。
5.  部署剩餘的機器機架。
6.  為面向用戶的服務分配資源，以便他們的團隊可以設定服務。

步驟 4 和 6 極其複雜。雖然像 DNS 這樣的基本服務相對簡單，但當時的儲存和計算子系統仍在大量開發中，因此每週都會增加新的標誌、組件和優化。

有些服務有一百多個不同的組件子系統，每個子系統都有一個複雜的依賴網路。未能配置一個子系統，或將一個系統或組件配置得與其他部署不同，都是一個等待發生的、影響客戶的中斷。

在一個案例中，一個數 PB 的 Bigtable 叢集被配置為出於延遲原因不使用 12 磁碟系統上的第一個（日誌）磁碟。一年後，一些自動化假設如果一台機器的第一個磁碟沒有被使用，那麼該機器就沒有配置任何儲存；因此，擦除該機器並從頭開始設定是安全的。所有的 Bigtable 資料都被立即擦除了。幸運的是，我們有多個該資料集的即時副本，但這樣的意外是不受歡迎的。自動化需要小心依賴隱含的「安全」信號。

早期的自動化專注於加速叢集交付。這種方法傾向於創造性地使用 SSH 來解決乏味的軟體包分發和服務初始化問題。這種策略最初取得了成功，但那些自由形式的腳本變成了技術債務的膽固醇。

## 用 Prodtest 檢測不一致性

隨著叢集數量的增長，一些叢集需要手動調整的標誌和設定。結果，團隊浪費了越來越多的時間來追查難以發現的配置錯誤。如果一個使 GFS 對日誌處理更具響應性的標誌洩漏到預設範本中，擁有大量檔案的單元在負載下可能會耗盡記憶體。幾乎每一次大的配置變更都會引入令人惱火且耗時的配置錯誤。

我們用來配置叢集的那些富有創意但脆弱的 shell 腳本，既無法擴展到想要進行變更的人數，也無法擴展到需要建構的叢集排列組合的數量。這些 shell 腳本在宣佈一個服務可以接受面向客戶的流量之前，也未能解決更重大的問題，例如：

- 服務的所有依賴項是否都可用且配置正確？
- 所有配置和軟體包是否與其他部署一致？
- 團隊能否確認每個配置例外都是期望的？

**Prodtest**（生產測試）是解決這些不受歡迎的意外的一個巧妙方案。我們擴展了 Python 單元測試框架，以允許對現實世界的服務進行單元測試。這些單元測試有依賴關係，允許形成一個測試鏈，一個測試的失敗會迅速中止。以圖 7-1 中顯示的測試為例。

給定團隊的 Prodtest 會被給予叢集名稱，它可以驗證該團隊在該叢集中的服務。後來的添加允許我們生成一個單元測試及其狀態的圖形。這個功能讓工程師可以快速查看他們的服務是否在所有叢集中都配置正確，如果不正確，原因是什麼。圖形會突出顯示失敗的步驟，而失敗的 Python 單元測試會輸出更詳細的錯誤訊息。

每當一個團隊因另一個團隊意外的配置錯誤而遇到延遲時，就可以提交一個錯誤來擴展他們的 Prodtest。這確保了類似的問題將來會更早被發現。SRE 很自豪能夠向他們的客戶保證，所有服務——無論是新啟用的服務還是具有新配置的現有服務——都能可靠地服務生產流量。

我們的專案經理第一次能夠預測一個叢集何時可以「上線」，並完全理解為什麼每個叢集從「網路就緒」到「服務即時流量」需要六週或更長時間。出乎意料的是，SRE 接到了一個來自高層管理的任務：在三個月內，五個新叢集將在同一天達到網路就緒。請在一周內將它們啟用。

## 冪等地解決不一致性

「一周啟用」是一個可怕的任務。我們有數萬行由數十個團隊擁有的 shell 腳本。我們可以很快地判斷出任何給定叢集的準備程度有多差，但要修復它意味著數十個團隊必須提交數百個錯誤，然後我們還得希望這些錯誤能被迅速修復。

我們意識到，從「Python 單元測試發現配置錯誤」演進到「Python 程式碼修復配置錯誤」可以讓我們更快地解決這些問題。

單元測試已經知道我們正在檢查哪個叢集以及哪個特定的測試失敗了，所以我們為每個測試配對了一個修復。如果每個修復都被寫成**冪等的 (idempotent)**，並且可以假設所有依賴項都已滿足，那麼解決問題應該是容易且安全的。要求冪等的修復意味著團隊可以每 15 分鐘運行一次他們的「修復腳本」，而不用擔心損壞叢集的配置。如果 DNS 團隊的測試被機器資料庫團隊對新叢集的配置所阻塞，一旦叢集出現在資料庫中，DNS 團隊的測試和修復就會開始工作。

以圖 7-2 所示的測試為例。如果 `TestDnsMonitoringConfigExists` 失敗，如圖所示，我們可以呼叫 `FixDnsMonitoringCreateConfig`，它會從資料庫中抓取配置，然後將一個骨架設定檔簽入我們的版本控制系統。然後 `TestDnsMonitoringConfigExists` 在重試時通過，就可以嘗試 `TestDnsMonitoringConfigPushed` 測試。如果該測試失敗，則運行 `FixDnsMonitoringPushConfig` 步驟。如果一個修復多次失敗，自動化會假設修復失敗並停止，通知用戶。

有了這些腳本，一小群工程師就能確保我們可以在一兩週內從「網路正常，機器已列入資料庫」到「服務 1% 的網頁搜尋和廣告流量」。當時，這似乎是自動化技術的頂峰。

回頭看，這種方法存在嚴重缺陷；測試、修復，然後再進行第二次測試之間的延遲引入了不穩定的測試，有時成功有時失敗。並非所有的修復都是天然冪等的，所以一個不穩定的測試後跟一個修復可能會使系統處於不一致的狀態。

## 專業化的傾向

自動化流程可以在三個方面有所不同：

- **能力 (Competence)**，即其準確性
- **延遲 (Latency)**，即啟動後所有步驟執行得多快
- **相關性 (Relevance)**，即自動化所涵蓋的真實世界流程的比例

我們開始時的流程是高度**稱職的**（由服務所有者維護和運行），**高延遲的**（服務所有者在他們的空閒時間執行該流程或將其分配給新工程師），並且非常**相關的**（服務所有者知道真實世界何時發生變化，並能修復自動化）。

為了減少啟用延遲，許多擁有服務的團隊指示一個單獨的「啟用團隊」來運行哪些自動化。啟用團隊使用工單來啟動啟用的每個階段，這樣我們就可以跟踪剩餘的任務，以及這些任務分配給了誰。如果關於自動化模組的人際互動發生在同一個房間裡的人之間，叢集啟用可以在短得多的時間內完成。最終，我們擁有了我們稱職、準確且及時的自動化流程！

但這種狀態並沒有持續多久。現實世界是混亂的：軟體、配置、資料等都在變化，導致受影響的系統每天有超過一千個單獨的變更。受自動化錯誤影響最大的人不再是領域專家，因此自動化變得**不那麼相關**（意味著新的步驟被錯過）和**不那麼稱職**（新的標誌可能會導致自動化失敗）。然而，這種品質下降對速度的影響需要一段時間才能顯現出來。

自動化程式碼，就像單元測試程式碼一樣，當維護團隊不執著於使其與所涵蓋的程式碼庫保持同步時，就會死亡。世界在程式碼周圍變化：DNS 團隊增加了新的配置選項，儲存團隊更改了他們的軟體包名稱，網路團隊需要支持新設備。

通過解除運行服務的團隊維護和運行其自動化程式碼的責任，我們製造了醜陋的組織激勵：

- 一個主要任務是加速當前啟用的團隊，沒有動力去減少服務擁有團隊在生產中運行服務時的技術債務。
- 一個不運行自動化的團隊，沒有動力去建立易於自動化的系統。
- 一個其排程不受低品質自動化影響的產品經理，將永遠優先考慮新功能，而不是簡單性和自動化。

功能最強大的工具通常是由使用它們的人編寫的。類似的論點也適用於為什麼產品開發團隊能從保持對其在生產中的系統至少一些運營意識中受益。

啟用再次變得高延遲、不準確和不稱職——這是所有世界中最糟糕的。然而，一個無關的安全指令讓我們擺脫了這個陷阱。當時，許多分散式自動化都依賴於 SSH。從安全角度來看，這很笨拙，因為人們必須在許多機器上擁有 root 權限才能運行大多數命令。對高級、持續性安全威脅的日益認識，促使我們將 SRE 享有的特權減少到他們完成工作所需的絕對最低限度。我們不得不將 sshd 的使用替換為一個經過身份驗證、基於 ACL、基於 RPC 的**本地管理守護進程 (Local Admin Daemon)**，也稱為**管理伺服器 (Admin Servers)**，它有權限執行那些本地變更。結果是，沒有人可以在沒有審計追蹤的情況下安裝或修改伺 poit。對本地管理守護進程和軟體包倉庫的更改都受到程式碼審查的限制，使得某人很難超越其權限；給予某人安裝軟體包的權限並不會讓他們查看位於同一地點的日誌。管理伺服器記錄了 RPC 請求者、任何參數以及所有 RPC 的結果，以增強除錯和安全審計。

## 面向服務的叢集啟用

在下一次迭代中，管理伺服器成為服務團隊工作流程的一部分，既涉及特定於機器的管理伺服器（用於安裝軟體包和重啟），也涉及叢集級別的管理伺服器（用於諸如排空或啟用服務等操作）。SRE 從在他們的家目錄中編寫 shell 腳本，轉變為建立經過同行評審的、具有細粒度 ACL 的 RPC 伺服器。

後來，在完全意識到啟用過程必須由擁有服務的團隊所擁有之後，我們將其視為一種解決叢集啟用問題的**服務導向架構 (Service-Oriented Architecture, SOA)** 方法：服務所有者將負責創建一個管理伺服器來處理叢集啟用/停用 RPC，這些 RPC 由知道叢集何時準備就緒的系統發送。反過來，每個團隊將提供啟用自動化所需的合約 (API)，同時仍然可以自由地更改底層實現。當一個叢集達到「網路就緒」時，自動化會向在啟用叢集中發揮作用的每個管理伺服器發送一個 RPC。

我們現在擁有一個低延遲、稱職且準確的流程；最重要的是，隨著變更率、團隊數量和服務數量的似乎每年都在翻倍，這個流程一直保持強勁。

如前所述，我們啟用自動化的演進遵循了一條路徑：

1.  **操作員觸發的手動操作**（無自動化）
2.  **操作員編寫的、特定於系統的自動化**
3.  **外部維護的通用自動化**
4.  **內部維護的、特定於系統的自動化**
5.  **無需人為干預的自主系統**

雖然這種演進總體上是成功的，但 Borg 的案例研究說明了我們思考自動化問題的另一種方式。

# Borg：倉庫規模計算機的誕生

理解我們對自動化態度的發展，以及自動化在何時何地部署最佳的另一種方式，是考慮我們叢集管理系統發展的歷史。31 就像 Borg 上的 MySQL 證明了將手動操作轉換為自動操作的成功，以及叢集啟用過程證明了沒有足夠仔細地思考自動化在何處以及如何實施的缺點一樣，開發叢集管理最終也證明了關於如何進行自動化的另一個教訓。像我們前面的兩個例子一樣，最終通過從更簡單的開端不斷演進，創造出了相當複雜的東西。

Google 的叢集最初的部署方式與當時其他所有人的小型網路非常相似：具有特定用途和異構配置的機器機架。工程師會登錄到一些眾所周知的「主」機器來執行管理任務；「黃金」二進位檔案和配置都存放在這些主機上。由於我們只有一個託管提供商，大多數命名邏輯都隱含地假設了那個位置。隨著生產的增長，以及我們開始使用多個叢集，不同的域（叢集名稱）進入了畫面。有必要有一個檔案來描述每台機器的作用，該檔案根據一些鬆散的命名策略將機器分組。這個描述符檔案，與相當於並行 SSH 的工具相結合，讓我們可以一次性重啟（例如）所有的搜尋機器。大約在那個時候，經常會收到像「搜尋已經用完機器 x1，爬蟲現在可以用這台機器了」這樣的工單。

自動化開發開始了。最初的自動化包括用於以下操作的簡單 Python 腳本：

- **服務管理**：保持服務運行（例如，段錯誤後重啟）
- **跟踪**哪些服務應該在哪台機器上運行
- **日誌訊息解析**：SSH 到每台機器並尋找正則表達式

自動化最終演變成一個正規的資料庫，用於跟踪機器狀態，並且還整合了更複雜的監控工具。有了可用的自動化聯合集，我們現在可以自動管理機器生命週期的大部分內容：注意到機器何時損壞，移除服務，將其送修，並在它們從維修回來時恢復配置。

但退一步說，這種自動化雖然有用，但卻有著深刻的局限性，因為系統的抽象與物理機器緊密地聯繫在一起。我們需要一種新的方法，因此 **Borg** [Ver15] 誕生了：一個擺脫了先前世界相對靜態的主機/埠/工作分配，轉向將機器集合視為一個受管理的資源海洋的系統。其成功和構思的核心是將叢集管理轉變為一個可以向某個中央協調器發出 API 呼叫的實體的概念。這釋放了效率、靈活性和可靠性的額外維度：與之前機器「所有權」的模型不同，Borg 可以允許機器在同一台機器上排程，例如，批次處理和面向用戶的任務。

這個功能最終導致了持續且自動的操作系統升級，而只需非常少量且固定的 32 精力——這種精力不會隨著生產部署的總規模而擴展。機器狀態的輕微偏差現在會被自動修復；損壞和生命週期管理在此時對 SRE 來說基本上是無操作。每天有數千台機器誕生、死亡並進入維修，而無需 SRE 的努力。借用 Ben Treynor Sloss 的話：通過將其視為一個軟體問題，最初的自動化為我們贏得了足夠的時間，將叢集管理轉變為**自主 (autonomous)** 的，而不是**自動化的 (automated)**。我們通過將與資料分佈、API、輻射型架構和經典分散式系統軟體開發相關的思想應用於基礎設施管理領域來實現這一目標。

這裡可以做一個有趣的類比：我們可以在單機情況和叢集管理抽象的發展之間建立一個直接的對應關係。在這種觀點下，在另一台機器上重新排程看起來很像一個進程從一個 CPU 移動到另一個 CPU：當然，那些計算資源恰好在網路連結的另一端，但這到底有多重要？從這個角度思考，重新排程看起來是系統的一個內在特徵，而不是人們會去「自動化」的東西——反正人類也反應不過來。叢集啟用的情況也類似：在這個比喻中，叢集啟用只是額外的可排程容量，有點像為單台計算機增加磁碟或 RAM。然而，單節點計算機通常不期望在大量組件發生故障時繼續運行。全球計算機則不同——由於基本上統計上保證每秒都有大量故障發生，一旦它增長超過一定規模，它就必須能夠自我修復才能運行。這意味著，當我們將系統從手動觸發，到自動觸發，再到自主的層次結構向上移動時，一些自我反省的能力對於生存是必要的。

# 可靠性是根本性特徵

當然，為了有效的故障排除，自省所依賴的內部操作細節也應該暴露給管理整個系統的人類。關於自動化在非計算機領域影響的類似討論——例如，在飛機飛行 33 或工業應用中——通常指出高效自動化的缺點：34 隨著時間的推移，自動化涵蓋了越來越多的日常活動，人類操作員越來越多地被剝奪了與系統的有用直接接觸。不可避免地，會出現自動化失敗的情況，而此時人類已無法成功操作該系統。由於缺乏練習，他們的反應流暢性已經喪失，他們對系統應該做什麼的心理模型也不再反映其正在做什麼的現實。35 當系統是非自主的時——即自動化取代了手動操作，並且假定手動操作總是像以前一樣可以執行和可用——這種情況更容易發生。可悲的是，隨著時間的推移，這最終變成了假的：那些手動操作並非總是可執行的，因為允許它們的功能已不復存在。

我們也曾多次遇到過自動化產生積極危害的情況——請參閱「自動化：大規模啟用故障」——但在 Google 的經驗中，有更多的系統，自動化或自主行為不再是可選的附加功能。當然，隨著規模的擴大，情況就是如此，但無論規模大小，仍然有強烈的理由支持系統更自主的行為。可靠性是根本性特徵，而自主、有彈性的行為是獲得這種可靠性的一種有用方式。

# 建議

您可能會閱讀本章中的例子，並決定在您與自動化有任何關係之前，您需要達到 Google 的規模。這是不正確的，原因有二：自動化提供的不僅僅是節省時間，因此在比簡單的時間花費與時間節省計算所建議的更多情況下，實施它是值得的。但槓桿作用最高的方法實際上發生在設計階段：快速發布和迭代可能會讓您更快地實現功能，但很少能造就一個有彈性的系統。自主操作很難令人信服地對足夠大的系統進行改造，但軟體工程中的標準良好實踐將大有裨益：擁有解耦的子系統、引入 API、最小化副作用等等。

Google 運行著十幾個自己的大型資料中心，但我們也依賴於許多第三方託管設施（或「colo」）中的機器。我們在這些 colo 中的機器用於終止大多數傳入的連接，或作為我們自己的內容分發網路的快取，以降低終端用戶的延遲。在任何時候，都有一些這樣的機架正在安裝或退役；這兩個過程都已基本自動化。退役期間的一個步驟涉及覆寫機架中所有機器的全部磁碟內容，之後一個獨立的系統會驗證擦除是否成功。我們稱這個過程為「Diskerase」。

曾幾何時，負責退役某個特定機架的自動化失敗了，但僅在 Diskerase 步驟成功完成後。後來，為了除錯該故障，退役過程從頭開始重新啟動。在那次迭代中，當試圖將機架中的機器集發送到 Diskerase 時，自動化確定仍然需要 Diskerase 的機器集（正確地）為空。不幸的是，空集被用作一個特殊值，被解釋為「所有東西」。這意味著自動化將我們在所有 colo 中的幾乎所有機器都發送到了 Diskerase。

幾分鐘內，高效的 Diskerase 擦除了我們 CDN 中所有機器的磁碟，這些機器再也無法終止來自用戶的連接（或做任何其他有用的事情）。我們仍然能夠從我們自己的資料中心為所有用戶提供服務，幾分鐘後，外部唯一可見的影響是延遲略有增加。據我們所知，很少有用戶注意到這個問題，這要歸功于良好的容量規劃（至少我們做對了！）。與此同時，我們花了將近兩天的時間重新安裝受影響的 colo 機架中的機器；然後我們花了接下來的幾週時間來審計和在我們的自動化中增加更多的健全性檢查——包括速率限制——並使我們的退役工作流程具有冪等性。

26 對於已經覺得自己精確理解自動化價值的讀者，請跳至「對 Google SRE 的價值」。然而，請注意，我們的描述包含一些細微之處，在閱讀本章其餘部分時記住這些細微之處可能會很有用。

27 在建立此類自動化過程中獲得的專業知識本身也很有價值；工程師既深刻理解他們已自動化的現有流程，又能在以後更快地自動化新穎的流程。

28 請參閱以下 XKCD 漫畫：https://xkcd.com/1205/。

29 例如，請參閱 https://blog.engineyard.com/2014/pets-vs-cattle。

30 當然，並非所有需要管理的系統都實際提供可呼叫的管理 API——這迫使一些工具使用，例如，CLI 調用或自動化的網站點擊。

31 我們為了便於理解，對這段歷史進行了壓縮和簡化。

32 指一個小的、不變的數字。

33 例如，請參閱 https://en.wikipedia.org/wiki/Air_France_Flight_447。

34 例如，請參閱 [Bai83] 和 [Sar97]。

35 這又是定期進行演習的另一個好理由；請參閱「災難角色扮演」。