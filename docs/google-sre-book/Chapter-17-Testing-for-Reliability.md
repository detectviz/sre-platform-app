# 可靠性測試

作者：Alex Perry 和 Max Luebbe 編輯：Diane Bates

> 如果你沒有試過，就假設它是壞的。
>
> 未知

網站可靠性工程師的一個關鍵職責是量化他們所維護系統的信心。SRE 通過將傳統的軟體測試技術應用於大規模系統來執行此任務。86 信心可以通過過去的可靠性和未來的可靠性來衡量。前者是通過分析監控歷史系統行為提供的資料來捕捉的，而後者則是通過對過去系統行為的資料進行預測來量化的。為了使這些預測足夠強大以至於有用，必須滿足以下條件之一：

- 網站隨著時間的推移完全保持不變，沒有軟體發布或伺服器機隊的變更，這意味著未來的行為將與過去的行為相似。
- 您可以自信地描述網站的所有變更，以便分析能夠考慮到每次變更所帶來的不確定性。

測試是您在發生變更時用來證明特定等效區域的機制。87 每個在變更前後都通過的測試都會減少分析需要考慮的不確定性。徹底的測試有助於我們以足夠詳細的程度預測給定網站的未來可靠性，使其具有實際用途。

您需要進行的測試量取決於您系統的可靠性要求。隨著您的程式碼庫被測試覆蓋的百分比增加，您會減少不確定性以及每次變更可能導致的可靠性下降。足夠的測試覆蓋率意味著您可以在可靠性降至可接受水平以下之前進行更多的變更。如果您過快地進行過多的變更，預測的可靠性會接近可接受的極限。此時，您可能需要停止進行變更，同時累積新的監控資料。累積的資料補充了經過測試的覆蓋範圍，從而驗證了為修訂後的執行路徑所斷言的可靠性。假設服務的客戶端是隨機分佈的 [Woo96]，抽樣統計可以從監控的指標中推斷出總體行為是否正在利用新的路徑。這些統計資料可以識別出需要更好測試或其他改進的領域。

通過一個測試或一系列測試並不一定能證明可靠性。然而，失敗的測試通常證明了**缺乏**可靠性。

監控系統可以發現錯誤，但速度僅限於報告管線的反應速度。**平均修復時間 (Mean Time to Repair, MTTR)** 衡量運營團隊修復錯誤所需的時間，無論是通過回滾還是其他操作。

測試系統有可能以零 MTTR 識別出一個錯誤。當一個系統級測試應用於一個子系統，並且該測試檢測到與監控會檢測到的完全相同的問題時，就會發生零 MTTR。這樣的測試可以阻止推送，因此該錯誤永遠不會到達生產環境（儘管它仍然需要在原始碼中修復）。通過阻止推送來修復零 MTTR 的錯誤既快速又方便。您能以零 MTTR 找到的錯誤越多，您的用戶體驗到的**平均無故障時間 (Mean Time Between Failures, MTBF)** 就越高。

隨著 MTBF 因更好的測試而增加，開發人員被鼓勵更快地發布功能。當然，其中一些功能會有錯誤。當這些新錯誤被發現和修復時，會導致對發布速度的相反調整。

撰寫關於軟體測試的作者們在需要什麼樣的覆蓋範圍上基本達成了一致。大多數意見衝突源於術語衝突、對測試在軟體生命週期各個階段影響的強調不同，或者他們進行測試的系統的特殊性。有關 Google 整體測試的討論，請參閱 [Whi12]。以下各節詳細說明了本章中與軟體測試相關的術語是如何使用的。

## 軟體測試的類型

軟體測試大致可分為兩類：傳統測試和生產測試。傳統測試在軟體開發中更為常見，用於在開發期間離線評估軟體的正確性。生產測試在一個即時的網頁服務上執行，以評估已部署的軟體系統是否正常工作。

## 傳統測試

如圖 17-1 所示，傳統的軟體測試始於單元測試。更複雜功能的測試則建立在單元測試之上。

### 單元測試

**單元測試 (Unit test)** 是最小、最簡單的軟體測試形式。這些測試用於評估一個可分離的軟體單元（如一個類別或函式）的正確性，獨立於包含該單元的較大軟體系統。單元測試也作為一種規範形式，以確保一個函式或模組完全執行系統所要求的行為。單元測試通常用於介紹測試驅動開發的概念。

### 整合測試

通過單個單元測試的軟體組件被組裝成更大的組件。然後，工程師對組裝好的組件運行**整合測試 (integration test)**，以驗證其功能是否正確。**依賴注入 (Dependency injection)**，通過像 Dagger 88 這樣的工具執行，是一種非常有用的技術，用於創建複雜依賴項的模擬物件，以便工程師可以乾淨地測試一個組件。一個常見的依賴注入例子是用一個具有精確指定行為的輕量級模擬來取代一個有狀態的資料庫。

### 系統測試

**系統測試 (System test)** 是工程師為未部署的系統運行的最大規模的測試。屬於特定組件的所有模組，例如一個通過了整合測試的伺服器，都被組裝到系統中。然後工程師測試系統的端到端功能。系統測試有多種不同的類型：

## 生產測試

**生產測試 (Production test)** 與一個即時的生產系統互動，而不是在一個密封的測試環境中。這些測試在許多方面類似於黑盒監控（請參閱「監控分散式系統」），因此有時也被稱為**黑盒測試 (black-box testing)**。生產測試對於運行一個可靠的生產服務至關重要。

人們常說測試應該在一個**密封的 (hermetic)** 環境中進行 [Nar12]。這句話意味著生產環境不是密封的。當然，生產環境通常不是密封的，因為推出節奏會以小的、易於理解的塊對生產環境進行即時更改。

為了管理不確定性並向用戶隱藏風險，變更可能不會按照它們被添加到原始碼控制中的順序即時推送。推出通常分階段進行，使用逐漸調動用戶的機制，並在每個階段進行監控，以確保新環境不會遇到預期之外的意外問題。因此，整個生產環境被有意地設計為不代表原始碼控制中任何給定版本的二進位檔案。

原始碼控制中可能有多個版本的二進位檔案及其相關的設定檔等待上線。當對即時環境進行測試時，這種情況可能會導致問題。例如，測試可能會使用位於原始碼控制中的最新版本的設定檔，以及一個較舊的、正在運行的二進位檔案。或者它可能會測試一個較舊版本的設定檔，並發現一個在新版本檔案中已修復的錯誤。

同樣，一個系統測試可以在運行測試之前使用設定檔來組裝其模組。如果測試通過，但其版本是配置測試（在下一節中討論）失敗的版本，那麼該測試的結果在密封環境中是有效的，但在操作上是無效的。這樣的結果是不方便的。

### 配置測試

在 Google，網頁服務的配置被描述在儲存在我們版本控制系統中的檔案中。對於每個設定檔，一個單獨的**配置測試 (configuration test)** 會檢查生產環境，以查看某個特定的二進位檔案實際上是如何配置的，並報告與該檔案的差異。此類測試本質上不是密封的，因為它們在測試基礎設施沙箱之外操作。

配置測試是針對已簽入的設定檔的特定版本來建置和測試的。比較哪個版本的測試正在通過與自動化的目標版本，可以隱含地指示實際生產目前落後於正在進行的工程工作的程度。

這些非密封的配置測試作為分散式監控解決方案的一部分往往特別有價值，因為跨生產環境的通過/失敗模式可以識別出服務堆疊中那些沒有合理本地配置組合的路徑。監控解決方案的規則試圖將實際用戶請求的路徑（來自追蹤日誌）與那組不受歡迎的路徑進行匹配。規則發現的任何匹配都會成為警報，表明正在進行的發布和/或推送不安全，需要採取補救措施。

當生產部署使用實際的檔案內容並提供一個即時查詢來檢索內容副本時，配置測試可以非常簡單。在這種情況下，測試程式碼只需發出該查詢，並將回應與檔案進行比較。當配置執行以下操作之一時，測試會變得更加複雜：

- 隱含地納入內建於二進位檔案中的預設值（這意味著測試因此被單獨版本化）
- 通過像 bash 這樣的預處理器傳遞到命令列標誌中（使得測試受制於擴展規則）
- 為共享的執行期指定行為上下文（使得測試依賴於該執行期的發布排程）

### 壓力測試

為了安全地操作一個系統，SRE 需要了解系統及其組件的極限。在許多情況下，單個組件在超過某個點後不會優雅地降級——而是會災難性地失敗。工程師使用**壓力測試 (stress tests)** 來尋找一個網頁服務的極限。壓力測試回答諸如以下問題：

- 一個資料庫在寫入開始失敗之前可以滿到什麼程度？
- 每秒可以向一個應用程式伺服器發送多少個查詢，才會使其過載，導致請求失敗？

### 金絲雀測試

**金絲T雀測試 (canary test)** 在這個生產測試列表中顯得格外引人注目。金絲雀這個詞來自於「煤礦裡的金絲雀」這句話，指的是在人類中毒之前，用一隻活鳥來檢測有毒氣體的做法。

要進行金絲雀測試，會將一部分伺服器升級到一個新版本或配置，然後讓它們處於一個**孵化期 (incubation period)**。如果沒有發生意外的偏差，發布將繼續，其餘的伺服器將以漸進的方式進行升級。89 如果出現任何問題，修改過的伺服器可以迅速恢復到一個已知的良好狀態。我們通常將升級後伺服器的孵化期稱為「烘烤二進位檔案 (baking the binary)」。

金絲雀測試並不是真正的測試；更確切地說，它是一種結構化的**用戶驗收 (user acceptance)**。配置和壓力測試確認了在確定性軟體上特定條件的存在，而金絲雀測試則更為臨時。它只將被測程式碼暴露於較不可預測的即時生產流量中，因此，它並不完美，也不總能捕捉到新引入的故障。

為了提供一個金絲雀測試如何進行的具體例子：考慮一個給定的、相對很少影響用戶流量的潛在故障，它正通過一個指數級的升級推出進行部署。我們預期報告的偏差的累積數量會不斷增長，`CU = RK`，其中 `R` 是這些報告的速率，`U` 是故障的階數（稍後定義），`K` 是流量以 `e`（或 172%）的倍數增長的週期。90

為了避免對用戶造成影響，觸發不良偏差的推出需要迅速回滾到先前的配置。在自動化觀察到偏差並做出回應的短時間內，很可能會產生幾個額外的報告。一旦塵埃落定，這些報告可以估計出累積數量 `C` 和速率 `R`。

除以 `K` 並進行校正，可以得到 `U` 的估計值，即潛在故障的**階數 (order)**。91 一些例子：

- **U=1**：用戶的請求遇到了 просто 壞掉的程式碼。
- **U=2**：該用戶的請求隨機損壞了未來用戶請求可能會看到的資料。
- **U=3**：隨機損壞的資料也是先前請求的有效識別碼。

大多數錯誤都是一階的：它們與用戶流量的數量成線性關係 [Per07]。您通常可以通過將所有具有異常回應的請求的日誌轉換為新的回歸測試來追蹤這些錯誤。這種策略對高階錯誤無效；一個如果在所有前面的請求都按順序嘗試時會重複失敗的請求，如果省略了某些請求，就會突然通過。在發布期間捕捉這些高階錯誤很重要，否則，運營工作負載可能會迅速增加。

在採用指數級推出策略時，請記住高階與低階錯誤的動態，不必試圖在用戶流量的各個部分之間實現公平。只要每種建立部分的方法都使用相同的 `K` 間隔，`U` 的估計值就是有效的，即使您還無法確定是哪種方法有助於闡明故障。順序使用多種方法，同時允許一些重疊，可以保持 `K` 的值較小。這種策略最小化了用戶可見的偏差總數 `C`，同時仍然允許對 `U` 進行早期估計（當然，希望是 1）。

# 創建測試和建置環境

雖然在專案的第一天就思考這些類型的測試和故障場景是非常棒的，但 SRE 經常在專案已經進行到相當程度時才加入開發團隊——一旦團隊的專案驗證了其研究模型，其函式庫證明了專案的底層演算法是可擴展的，或者也許當所有的用戶介面模型最終都可接受時。團隊的程式碼庫仍然是一個原型，全面的測試還沒有被設計或部署。在這種情況下，你的測試工作應該從哪裡開始呢？如果當前的測試覆蓋率很低或不存在，為每個關鍵函式和類別進行單元測試是一個完全壓倒性的前景。相反，從以最少努力提供最大影響的測試開始。

您可以通過問以下問題來開始您的方法：

- 您能以任何方式對程式碼庫進行優先排序嗎？借用功能開發和專案管理的一種技巧，如果每個任務都是高優先級，那麼就沒有一個任務是高優先級。您能以任何重要性指標對您正在測試的系統的組件進行排序嗎？
- 是否有特定的函式或類別絕對是任務關鍵型或業務關鍵型的？例如，涉及計費的程式碼通常是業務關鍵型的。計費程式碼也經常可以與系統的其他部分乾淨地分離開來。
- 其他團隊正在與哪些 API 進行整合？即使是那種從未通過發布測試到達用戶的損壞，如果它讓另一個開發團隊感到困惑，導致他們為您的 API 編寫錯誤（甚至只是次優）的客戶端，也可能是極其有害的。

發布明顯損壞的軟體是開發人員最嚴重的罪過之一。為每次發布創建一系列**冒煙測試 (smoke tests)** 並不需要太多努力。這種低投入、高影響的第一步可以帶來經過高度測試、可靠的軟體。

建立強大測試文化的一種方法是開始將所有報告的錯誤記錄為測試案例。如果每個錯誤都被轉換為一個測試，那麼每個測試最初都應該會失敗，因為錯誤尚未被修復。隨著工程師修復錯誤，軟體通過測試，您就走上了開發一個全面的**回歸測試套件 (regression test suite)** 的道路。

創建經過良好測試的軟體的另一個關鍵任務是建立一個測試基礎設施。強大測試基礎設施的基礎是一個**版本化的原始碼控制系統**，該系統跟踪程式碼庫的每一次變更。

一旦有了原始碼控制，您就可以添加一個**持續建置系統 (continuous build system)**，該系統在每次提交程式碼時都會建置軟體並運行測試。我們發現，如果建置系統在變更破壞軟體專案的那一刻就通知工程師，效果是最佳的。冒著聽起來顯而易見的風險，原始碼控制中最新版本的軟體專案完全正常工作是至關重要的。當建置系統通知工程師程式碼損壞時，他們應該放下所有其他任務，並優先修復問題。出於幾個原因，如此嚴肅地對待缺陷是適當的：

- 如果在缺陷引入後對程式碼庫進行了更改，通常更難修復損壞的地方。
- 損壞的軟體會拖慢團隊的速度，因為他們必須繞過損壞的地方工作。
- 發布節奏，例如每夜和每週的建置，失去了它們的價值。
- 團隊回應緊急發布請求（例如，回應安全漏洞披露）的能力變得更加複雜和困難。

傳統上，穩定性和敏捷性的概念在 SRE 的世界中是緊張對立的。最後一個要點提供了一個有趣的案例，其中穩定性實際上推動了敏捷性。當建置可預測地堅固可靠時，開發人員可以更快地迭代！

一些像 Bazel 93 這樣的建置系統具有寶貴的功能，可以對測試進行更精確的控制。例如，Bazel 為軟體專案創建依賴關係圖。當對一個檔案進行更改時，Bazel 只會重新建置依賴於該檔案的軟體部分。這樣的系統提供了**可重現的建置 (reproducible builds)**。測試不是在每次提交時都運行所有測試，而只針對更改的程式碼運行。結果，測試執行得更便宜、更快。

有各種各樣的工具可以幫助您量化和視覺化您需要的測試覆蓋率水平 [Cra10]。使用這些工具來塑造您的測試重點：將創建經過高度測試的程式碼的前景視為一個工程專案，而不是一個哲學性的腦力練習。不要重複含糊不清的口頭禪「我們需要更多的測試」，而是設定明確的目標和截止日期。

請記住，並非所有軟體都是生而平等的。生命攸關或收入攸關的系統需要比具有短暫生命週期的非生產性腳本高得多的測試品質和覆蓋率。

# 大規模測試

既然我們已經介紹了測試的基礎知識，現在讓我們來看看 SRE 如何從系統的角度來進行測試，以推動大規模的可靠性。

一個小型的單元測試可能有一份簡短的依賴列表：一個原始檔、測試函式庫、執行期函式庫、編譯器以及運行測試的本地硬體。一個強健的測試環境要求這些依賴項各自都有自己的測試覆蓋範圍，並且有專門針對環境其他部分期望的用例的測試。如果該單元測試的實現依賴於一個沒有測試覆蓋範圍的執行期函式庫內的程式碼路徑，那麼環境中一個不相關的變更 94 可能會導致該單元測試始終通過測試，而不管被測程式碼中是否存在故障。

相比之下，一個發布測試可能依賴於如此多的部分，以至於它對程式碼儲存庫中的每個物件都有一個傳遞性的依賴關係。如果測試依賴於一個乾淨的生產環境副本，那麼原則上，每個小的補丁都需要執行一次完整的災難恢復迭代。實際的測試環境會嘗試在版本和合併之間選擇分支點。這樣做可以在最少的迭代次數內解決最大量的不確定性。當然，當一個不確定性領域解析為一個故障時，您需要選擇額外的分支點。

## 測試可擴展工具

作為軟體的一部分，SRE 工具也需要測試。95 SRE 開發的工具可能執行以下任務：

- 檢索和傳播資料庫性能指標
- 預測使用指標以規劃容量風險
- 在用戶無法存取的服務副本內重構資料
- 更改伺服器上的檔案

SRE 工具有兩個共同的特點：

- 它們的副作用保持在經過測試的主流 API 範圍內
- 它們通過現有的驗證和發布屏障與面向用戶的生產環境隔離

繞過通常經過嚴格測試的 API 的軟體（即使是出於好意）可能會對即時服務造成嚴重破壞。例如，一個資料庫引擎的實現可能允許管理員暫時關閉交易以縮短維護窗口。如果這個實現被批次更新軟體使用，那麼如果該實用程式意外地針對面向用戶的副本啟動，面向用戶的隔離性可能會喪失。通過設計來避免這種破壞的風險：

- 使用一個單獨的工具在複製配置中設置一個屏障，這樣副本就無法通過其健康檢查。結果，該副本不會被釋放給用戶。
- 配置有風險的軟體在啟動時檢查該屏障。允許有風險的軟體只存取不健康的副本。
- 使用您用於黑盒監控的副本健康驗證工具來移除該屏障。

自動化工具也是軟體。由於它們的風險足跡出現在服務的不同層次的帶外，它們的測試需求更為微妙。自動化工具執行諸如以下任務：

- 資料庫索引選擇
- 資料中心之間的負載平衡
- 為快速重新主控而洗牌中繼日誌

自動化工具有兩個共同的特點：

- 實際執行的操作是針對一個強健、可預測且經過良好測試的 API
- 操作的目的是一個副作用，即對另一個 API 客戶端來說是不可見的不連續性

測試可以證明另一個服務層在變更前後的期望行為。通常可以測試內部狀態（通過 API 觀察）在整個操作過程中是否保持不變。例如，即使沒有可用的查詢索引，資料庫也會追求正確的答案。另一方面，一些記錄在案的 API 不變量（例如 DNS 快取保持到 TTL）在操作過程中可能不成立。例如，如果一個運行級別的變更用一個快取代理取代了本地名稱伺服器，兩種選擇都可以承諾將完成的查找保留許多秒。快取狀態不太可能從一個轉移到另一個。

鑑於自動化工具意味著其他二進位檔案需要額外的發布測試來處理環境的瞬變，您如何定義那些自動化工具運行的環境？畢竟，如果用於洗牌容器以提高利用率的自動化本身也運行在一個容器中，它很可能會在某個時候嘗試洗牌自己。如果其內部演算法的一個新版本如此迅速地產生了髒記憶體頁，以至於相關鏡像的網路頻寬最終阻止了程式碼完成即時遷移，那將會很尷尬。即使有一個整合測試，其中二進位檔案有意地自我洗牌，該測試也可能不會使用生產規模的容器機隊模型。它幾乎肯定不被允許使用稀缺的高延遲洲際頻寬來測試此類競爭。

更有趣的是，一個自動化工具可能正在改變另一個自動化工具運行的環境。或者兩個工具可能同時改變對方自動化工具的環境！例如，一個機隊升級工具在推送升級時可能會消耗最多的資源。結果，容器重新平衡工具會傾向於移動該工具。反過來，容器重新平衡工具有時也需要升級。如果相關的 API 具有重啟語義，有人記得為這些語義實現測試覆蓋，並且檢查點的健康狀況得到獨立保證，那麼這種循環依賴是沒有問題的。

## 測試災難

許多災難恢復工具可以被精心設計為**離線 (offline)** 操作。此類工具執行以下操作：

- 計算一個相當於乾淨地停止服務的**檢查點 (checkpoint)** 狀態
- 將檢查點狀態推送到可由現有的非災難驗證工具**加載 (loadable)**
- 支持通常的**發布屏障 (release barrier)** 工具，這些工具會觸發乾淨的啟動程序

在許多情況下，您可以實現這些階段，使得相關的測試易於編寫並提供出色的覆蓋範圍。如果必須打破任何約束（離線、檢查點、可加載、屏障或乾淨啟動），那麼要證明相關工具的實現在任何時候都能在短時間內正常工作，就會困難得多。

**線上修復 (Online repair)** 工具本質上是在主流 API 之外操作的，因此測試起來更有趣。在一個分散式系統中，您面臨的一個挑戰是確定本質上可能是**最終一致的 (eventually consistent)** 正常行為是否會與修復產生不良互動。例如，考慮一個您可以使用離線工具嘗試分析的競爭條件。離線工具通常被編寫為期望**即時一致性 (instant consistency)**，而不是最終一致性，因為即時一致性測試起來不那麼具有挑戰性。這種情況變得複雜，因為修復二進位檔案通常與其正在競爭的服務生產二進位檔案分開建構。因此，您可能需要在這些測試中建構一個統一的儀器化二進位檔案，以便工具可以觀察交易。

統計技術，例如用於模糊測試的 Lemon [Ana07]，以及用於分散式狀態的 Chaos Monkey 96 和 Jepsen 97，不一定是可重複的測試。僅僅在程式碼變更後重新運行此類測試並不能明確證明觀察到的故障已修復。98 然而，這些技術可能很有用：

- 它們可以提供在給定運行中採取的所- **它們可以提供在給定運行中採取的所有隨機選擇的操作的日誌**——有時僅僅通過記錄隨機數生成器的種子。
- **如果這個日誌立即被重構為一個發布測試**，在開始處理錯誤報告之前運行幾次通常很有幫助。重播時的無故障率告訴您以後斷言故障已修復的難度。
- **故障表達方式的變化**有助於您查明程式碼中的可疑區域。
- **其中一些後來的運行可能會展示出比原始運行中更嚴重的故障情況**。作為回應，您可能需要升級該錯誤的嚴重性和影響。

## 速度的需求

對於程式碼儲存庫中的每個版本（補丁），每個定義的測試都會提供一個通過或失敗的指示。對於重複且看似相同的運行，該指示可能會改變。您可以通過對多次運行進行平均，並計算該可能性的統計不確定性，來估計一個測試通過或失敗的實際可能性。然而，在每個版本點對每個測試執行此計算在計算上是不可行的。

相反，您必須對許多感興趣的場景形成假設，並運行適當數量的每個測試和版本的重複，以允許進行合理的推斷。其中一些場景是良性的（在程式碼品質的意義上），而另一些則是可操作的。這些場景在不同程度上影響所有測試嘗試，並且由於它們是耦合的，可靠且快速地獲取可操作假設的列表（即，實際損壞的組件）意味著同時估計所有場景。

使用測試基礎設施的工程師想知道他們的程式碼——通常只是給定測試運行背後所有原始碼的一小部分——是否損壞。通常，沒有損壞意味著任何觀察到的失敗都可以歸咎於別人的程式碼。換句話說，工程師想知道他們的程式碼是否存在未預料到的競爭條件，使得測試不穩定（或者比測試由於其他因素已經存在的不穩定性更不穩定）。

大多數測試都是簡單的，因為它們作為一個自包含的密封二進位檔案運行，可以在一個小的計算容器中運行幾秒鐘。這些測試在工程師切換到下一個錯誤或任務之前，為他們提供關於錯誤的互動式反饋。

需要跨多個二進位檔案和/或跨擁有多個容器的機隊進行編排的測試，其啟動時間通常以秒為單位。此類測試通常無法提供互動式反饋，因此可以歸類為**批次測試 (batch tests)**。這些測試失敗不是對工程師說「不要關閉編輯器標籤」，而是對程式碼審查者說「此程式碼尚未準備好進行審查」。

測試的非正式截止日期是工程師進行下一次上下文切換的點。測試結果最好在工程師切換上下文之前提供給他或她，因為否則下一個上下文可能涉及 XKCD 編譯。99

假設一位工程師正在開發一個擁有超過 21,000 個簡單測試的服務，並偶爾針對該服務的程式碼庫提出一個補丁。為了測試該補丁，您希望將補丁前程式碼庫的通過/失敗結果向量與補丁後程式碼庫的結果向量進行比較。這兩個向量的良好比較可以初步認定該程式碼庫是可發布的。這種認定會產生一個激勵，去運行許多發布和整合測試，以及其他檢查系統擴展性（以防補丁使用顯著更多的本地計算資源）和複雜性（以防補丁在其他地方產生超線性工作負載）的分散式二進位測試。

您以多大的比率會因為錯誤地計算了環境的不穩定性而將用戶的補丁標記為有害？如果每 10 個補丁中有 1 個被拒絕，用戶似乎很可能會強烈抱怨。但是，在 100 個完美的補丁中拒絕 1 個，可能就不會有人評論了。

這意味著您關心的是 0.99（被接受的補丁的比例）的 42,000 次方根（每個定義的測試在補丁前一次，補丁後一次）。這個計算：

`0.99 ^ (1 / 42000) = 0.99999976...`

表明那些單獨的測試必須在 99.9999% 的時間內正確運行。嗯。

## 推送到生產環境

雖然生產配置管理通常保存在原始碼控制儲存庫中，但配置通常與開發人員的原始碼是分開的。同樣，軟體測試基礎設施通常看不到生產配置。即使兩者位於同一個儲存庫中，配置管理的變更也是在分支和/或一個隔離的目錄樹中進行的，而測試自動化歷來都忽略了這些。

在一個傳統的企業環境中，軟體工程師開發二進位檔案，然後把它們「扔過牆」給更新伺服器的管理員，測試基礎設施和生產配置的分離充其量是令人討厭的，最壞的情況下會損害可靠性和敏捷性。這種分離也可能導致工具的重複。在一個名義上整合的運營環境中，這種分離會降低彈性，因為它在兩套工具的行為之間造成了細微的不一致。這種分離也限制了專案的速度，因為版本控制系統之間存在提交競爭。

在 SRE 模型中，將測試基礎設施與生產配置分離的影響要明顯更糟，因為它妨礙了將描述生產的模型與描述應用程式行為的模型關聯起來。這種差異影響了那些希望在開發時發現期望中統計不一致的工程師。然而，這種分離並不會減慢開發速度，而是阻止了系統架構的改變，因為沒有辦法消除遷移風險。

考慮一個統一版本控制和統一測試的場景，這樣 SRE 方法論就適用了。一個分散式架構遷移的失敗會產生什麼影響？可能會進行大量的測試。到目前為止，我們假設一個軟體工程師可能會接受測試系統每 10 次左右給出一次錯誤答案。如果你知道測試可能會返回一個假陰性，並且情況可能會很快變得非常刺激，你願意為這次遷移承擔多大的風險？顯然，某些測試覆蓋領域需要比其他領域更高程度的偏執。這種區別可以推廣：一些測試失敗比其他測試失敗更能預示更大的影響風險。

## 預期測試失敗

不久前，一個軟體產品可能每年才發布一次。它的二進位檔案是由一個編譯器工具鏈在數小時或數天內生成的，大部分測試是由人類根據手動編寫的說明書進行的。這個發布過程效率低下，但沒有必要將其自動化。發布工作主要由文件、資料遷移、用戶再培訓和其他因素主導。這些發布的**平均無故障時間 (Mean Time Between Failure, MTBF)** 是一年，無論進行了多少測試。每次發布都有如此多的變更，以至於一些用戶可見的損壞必然會隱藏在軟體中。實際上，上一次發布的可靠性資料對於下一次發布是無關緊要的。

有效的 API/ABI 管理工具和能夠擴展到大量程式碼的解釋性語言，現在支援在幾分鐘內建置和執行一個新的軟體版本。原則上，一支足夠龐大的人類軍隊 100 可以使用前面描述的方法對每個新版本完成測試，並為每個增量版本達到相同的品質標準。儘管最終只有相同的測試應用於相同的程式碼，但最終的軟體版本在每年發布的結果版本中具有更高的品質。這是因為除了年度版本外，程式碼的中間版本也在被測試。使用中間版本，您可以明確地將測試中發現的問題對應到其根本原因，並確信整個問題，而不僅僅是暴露出來的有限症狀，都已得到修復。這種較短的反饋週期原則在應用於自動化測試覆蓋時同樣有效。

如果你讓用戶在一年內嘗試更多版本的軟體，MTBF 會受到影響，因為有更多機會出現用戶可見的損壞。然而，你也可以發現那些可以從額外的測試覆蓋中受益的領域。如果這些測試得以實施，每一次改進都會保護未來的某個故障。謹慎的可靠性管理將測試覆蓋帶來的不確定性限制與用戶可見的故障限制相結合，以調整發布節奏。這種結合最大化了你從運營和終端用戶那裡獲得的知識。這些收穫推動了測試覆蓋，進而推動了產品發布速度。

如果一個 SRE 修改了一個設定檔或調整了一個自動化工具的策略（而不是實現一個用戶功能），這個工程工作就符合同樣的概念模型。當您根據可靠性來定義一個發布節奏時，按功能，或（更方便地）按團隊來劃分可靠性預算通常是有意義的。在這樣一個場景中，功能工程團隊旨在達到一個給定的不確定性限制，這個限制會影響他們的目標發布節奏。SRE 團隊有一個單獨的預算，有其自身相關的不確定性，因此對其發布率有一個上限。

為了保持可靠並避免 SRE 支援一個服務的數量線性擴展，生產環境必須大部分時間無人值守。為了保持無人值守，環境必須對輕微的故障具有彈性。當發生需要 SRE 手動干預的重大事件時，SRE 使用的工具必須經過適當的測試。否則，該干預會降低對歷史資料適用於不久將來的信心。信心的降低需要等待對監控資料的分析，以消除所產生的不確定性。鑑於「測試可擴展工具」中前面的討論側重於如何滿足 SRE 工具的測試覆蓋機會，在這裡您可以看到，測試決定了對生產環境使用該工具的頻率是否合適。

設定檔通常存在是因為更改配置比重建工具更快。這種低延遲通常是保持 MTTR 較低的一個因素。然而，這些相同的檔案也經常因為不需要那種低延遲的原因而被頻繁更改。從可靠性的角度來看：

- 一個為了保持低 MTTR 而存在的設定檔，並且只在出現故障時才被修改，其發布節奏比 MTBF 要慢。對於一個給定的手動編輯是否真正是最佳的，在不影響整體網站可靠性的情況下，可能存在相當大的不確定性。
- 一個在每個面向用戶的應用程式發布中更改不止一次的設定檔（例如，因為它持有發布狀態）可能是一個主要風險，如果這些更改不被視為與應用程式發布相同。如果該設定檔的測試和監控覆蓋率沒有顯著優於用戶應用程式，該檔案將以負面的方式主導網站的可靠性。

處理設定檔的一種方法是確保每個設定檔只屬於前面項目列表中的一個選項，並以某種方式強制執行該規則。如果您採取後一種策略，請確保以下幾點：

- 每個設定檔都有足夠的測試覆蓋率來支持常規的例行編輯。
- 在發布之前，檔案編輯會因為等待發布測試而有所延遲。
- 提供一個**緊急機制 (break-glass mechanism)**，以便在完成測試之前將檔案推送到線上。由於打破玻璃會損害可靠性，因此通過（例如）提交一個錯誤報告，請求下次提供更可靠的解決方案，來讓這次破例變得引人注目，通常是一個好主意。

您可以實施一個緊急機制來禁用發布測試。這樣做意味著，任何進行倉促手動編輯的人，在真正的用戶影響被監控報告出來之前，都不會被告知任何錯誤。最好是讓測試繼續運行，將早期推送事件與待處理的測試事件關聯起來，並（盡快地）用任何損壞的測試來反向註釋該推送。這樣，一個有缺陷的手動推送可以很快地被另一個（希望缺陷較少的）手動推送所取代。理想情況下，該緊急機制會自動提高那些發布測試的優先級，以便它們可以搶占測試基礎設施已經在處理的常規增量驗證和覆蓋率工作負載。

## 整合

除了對設定檔進行單元測試以降低其對可靠性的風險外，考慮對設定檔進行整合測試也很重要。設定檔的內容（出於測試目的）對於讀取配置的解釋器來說可能是潛在的敵意內容。像 Python 這樣的解釋性語言通常用於設定檔，因為它們的解釋器可以被嵌入，並且有一些簡單的沙箱可用於防止非惡意的程式碼錯誤。

用一種解釋性語言來編寫你的設定檔是有風險的，因為這種方法充滿了難以明確解決的潛在故障。由於加載內容實際上包括執行一個程式，因此加載的效率沒有固有的上限。除了任何其他測試之外，你應該將這種類型的整合測試與對所有整合測試方法的仔細的截止日期檢查相結合，以便將未在合理時間內完成的測試標記為失敗。

如果配置改為以自訂語法的文本形式編寫，則每個類別的測試都需要從頭開始進行單獨的覆蓋。使用像 YAML 這樣的現有語法，並結合像 Python 的 `safe_load` 這樣經過大量測試的解析器，可以減少設定檔帶來的一些瑣務。仔細選擇語法和解析器可以確保加載操作所需的時間有一個嚴格的上限。然而，實現者需要解決模式錯誤，而大多數簡單的策略都沒有運行時的上限。更糟糕的是，這些策略往往沒有經過可靠的單元測試。

使用**協定緩衝區 (protocol buffers)** 101 的好處是，模式是預先定義的，並在加載時自動檢查，從而消除了更多的瑣務，同時仍然提供了有界的運行時。

SRE 的角色通常包括編寫系統工程工具 102（如果沒有其他人已經在編寫它們的話），並增加具有測試覆蓋率的可靠驗證。所有工具都可能因為測試未捕捉到的錯誤而出現意外行為，因此**深度防禦 (defense in depth)** 是可取的。當一個工具出現意外行為時，工程師需要盡可能確信他們的大多數其他工具都工作正常，因此可以緩解或解決該不當行為的副作用。交付網站可靠性的一個關鍵要素是找到每種預期的不當行為形式，並確保某個測試（或其他工具經過測試的輸入驗證器）報告該不當行為。發現問題的工具可能無法修復甚至停止它，但至少應該在災難性中斷發生之前報告問題。

例如，考慮所有用戶的配置列表（例如，在非網路化的 Unix 風格機器上的 `/etc/passwd`），並想像一個編輯無意中導致解析器在僅解析了一半檔案後就停止了。由於最近創建的用戶尚未加載，機器很可能會繼續正常運行，許多用戶可能不會注意到這個故障。維護家目錄的工具可以很容易地注意到實際存在的目錄與（部分的）用戶列表所暗示的目錄之間的不匹配，並緊急報告這種差異。這個工具的價值在於報告問題，它應該避免嘗試自行補救（通過刪除大量用戶資料）。

## 生產探測器

鑑於測試是在已知資料的情況下指定可接受的行為，而監控則是在未知用戶資料的情況下確認可接受的行為，似乎主要的風險來源——無論是已知的還是未知的——都已被測試和監控的組合所覆蓋。不幸的是，實際的風險要複雜得多。

已知的良好請求應該能正常工作，而已知的錯誤請求應該會出錯。將這兩種覆蓋範圍都作為整合測試來實現通常是一個好主意。您可以將同一組測試請求作為發布測試來重播。將已知的良好請求分為可以對生產環境重播和不能對生產環境重播的，可以得到三組請求：

- 已知的錯誤請求
- 已知的、可以對生產環境重播的良好請求
- 已知的、不能對生產環境重播的良好請求

您可以將每一組都用作整合測試和發布測試。這些測試中的大多數也可以用作監控探測器。

部署這樣的監控似乎是多餘的，而且原則上是沒有意義的，因為這些完全相同的請求已經用另外兩種方式嘗試過了。然而，這兩種方式在幾個方面是不同的：

- 發布測試可能用一個前端和一個假的後端來包裝整合後的伺服器。
- 探測測試可能用一個負載平衡前端和一個單獨的可擴展的持久性後端來包裝發布的二進位檔案。
- 前端和後端可能有獨立的發布週期。這些週期的排程很可能以不同的速率發生（由於它們的自適應發布節奏）。

因此，在生產環境中運行的監控探測器是一個以前沒有測試過的配置。

那些探測器永遠不應該失敗，但如果它們真的失敗了，這意味著什麼？要麼是前端 API（來自負載均衡器）或後端 API（到持久性儲存）在生產和發布環境之間不相等。除非您已經知道為什麼生產和發布環境不相等，否則網站很可能已經損壞。

同一個生產更新程式逐漸替換應用程式，也逐漸替換探測器，這樣所有四種組合——新舊探測器向新舊應用程式發送請求——都在持續生成。該更新程式可以檢測到四種組合中的一種正在產生錯誤，並回滾到最後一個已知的良好狀態。通常，更新程式期望每個新啟動的應用程式實例在準備開始接收大量用戶流量時，會在短時間內處於不健康狀態。如果探測器已經作為就緒性檢查的一部分被檢查，更新會安全地無限期失敗，並且沒有用戶流量會被路由到新版本。更新會一直暫停，直到工程師有時間和意願去診斷故障情況，然後鼓勵生產更新程式乾淨地回滾。

這種通過探測器進行的生產測試確實為網站提供了保護，並為工程師提供了清晰的反饋。反饋給工程師越早，就越有用。最好是將測試自動化，這樣向工程師發出警告的傳遞就是可擴展的。

假設每個組件都有正在被替換的舊軟體版本和正在推出的新版本（現在或很快）。新版本可能正在與舊版本的對等體通信，這迫使它使用已棄用的 API。或者舊版本可能正在與對等體的新版本通信，使用在舊版本發布時還沒有正常工作的 API。但現在它能工作了，真的！你最好希望那些用於未來相容性的測試（作為監控探測器運行）有很好的 API 覆蓋率。

在實施發布測試時，假的後端通常由對等服務的工程團隊維護，並且僅僅作為一個建置依賴項被引用。由測試基礎設施執行的密封測試總是將假的後端和測試前端在版本控制歷史的同一個建置點上結合起來。

該建置依賴項可能提供一個可運行的密封二進位檔案，理想情況下，維護它的工程團隊會在他們發布其主要後端應用程式及其探測器的同時，也發布該假後端二進位檔案的一個版本。如果該後端版本可用，那麼在前端發布包中包含密封的前端發布測試（沒有假後端二進位檔案）可能是值得的。

您的監控應該了解兩個對等體之間給定服務介面兩側的所有發布版本。這種設定確保了檢索兩個發布的每個組合併確定測試是否仍然通過，不需要太多的額外配置。這種監控不必持續進行——您只需要運行由任一團隊發布新版本所產生的新組合。此類問題不必阻止該新版本本身的發布。

另一方面，推出自動化理想情況下應該阻止相關的生產推出，直到有問題的組合不再可能。同樣，對等團隊的自動化可能會考慮排空（和升級）尚未從有問題的組合中移出的副本。

# 結論

測試是工程師為提高其產品可靠性所能進行的最有利可圖的投資之一。測試不是在專案生命週期中發生一兩次的活動；它是持續的。編寫好的測試所需的精力是巨大的，建立和維護促進強大測試文化的基礎設施所需的精力也是如此。在理解問題之前，你無法解決問題，而在工程領域，你只能通過測量來理解問題。本章中的方法論和技術為測量軟體系統中的故障和不確定性提供了堅實的基礎，並幫助工程師在編寫軟體並將其發布給用戶時，對軟體的可靠性進行推理。

86 本章解釋了如何最大化將工程精力投入到測試中所獲得的價值。一旦工程師以一種通用的方式為（給定的系統）定義了合適的測試，剩下的工作在所有 SRE 團隊中都是共同的，因此可以被視為共享的基礎設施。該基礎設施包括一個排程器（用於在原本不相關的專案之間共享預算資源）和執行器（用於沙箱化測試二進位檔案，以防止它們被視為受信任的）。這兩個基礎設施組件都可以被視為一個普通的 SRE 支持的服務（很像叢集規模的儲存），因此在此不再進一步討論。

87 有關等價的進一步閱讀，請參閱 https://stackoverflow.com/questions/1909280/equivalence-class-testing-vs-boundary-value-testing。

88 請參閱 https://dagger.dev/。

89 一個標準的經驗法則是，從讓發布影響 0.1% 的用戶流量開始，然後每 24 小時以數量級擴大規模，同時改變被升級的伺服器的地理位置（然後在第 2 天：1%，第 3 天：10%，第 4 天：100%）。

90 例如，假設在 1% 和 10% 之間有 24 小時的持續指數增長間隔，秒，或約 10 小時 25 分鐘。

91 我們在這裡使用「階」的意義是「大 O 符號」的複雜度階。更多背景資訊，請參閱 https://en.wikipedia.org/wiki/Big_O_notation。

92 關於這個主題的更多資訊，我們強烈推薦我們的[前同事和前 Google 員工 Mike Bland 的 [Bla14]。

93 請參閱 https://github.com/google/bazel。

94 例如，被測程式碼包裝了一個非平凡的 API，以提供一個更簡單且向後相容的抽象。以前是同步的 API 現在返回一個 future。呼叫參數錯誤仍然會引發異常，但要等到 future 被求值時。被測程式碼將 API 結果直接傳回給呼叫者。許多參數誤用的情況可能不會被捕捉到。

95 本節專門討論 SRE 使用的需要可擴展的工具。然而，SRE 也開發和使用不一定需要可擴展的工具。不需要可擴展的工具也需要被測試，但這些工具不在本節的範圍內，因此在此不再討論。由於它們的風險足跡與面向用戶的應用程式相似，類似的測試策略也適用於此類 SRE 開發的工具。

96 請參閱 https://github.com/Netflix/SimianArmy/wiki/Chaos-Monkey。

97 請參閱 https://github.com/aphyr/jepsen。

98 即使測試運行以相同的隨機種子重複，以便任務終止的順序相同，終止和假的用戶流量之間也沒有序列化。因此，不能保證實際先前觀察到的程式碼路徑現在會再次被執行。

99 請參閱 https://xkcd.com/303/。

100 也許是通過 Mechanical Turk 或類似的服務獲得的。

101 請參閱 https://github.com/google/protobuf。

102 並非因為軟體工程師不應該編寫它們。跨越技術垂直領域並跨越抽象層的工具，傾向於與許多軟體團隊有較弱的關聯，而與系統團隊有稍強的關聯。