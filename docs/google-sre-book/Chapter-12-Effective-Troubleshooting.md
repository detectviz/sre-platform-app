# 高效的故障排除

作者：Chris Jones

> 請注意，成為專家不僅僅是理解一個系統應該如何工作。專業知識是通過調查一個系統為何**不**工作而獲得的。
>
> Brian Redman

> 事情順利進行的方式是事情出錯方式的特例。
>
> John Allspaw

故障排除對於任何操作分散式計算系統的人來說都是一項關鍵技能——尤其是 SRE——但它通常被視為一種某些人有而其他人沒有的與生俱來的技能。這種假設的一個原因是，對於那些經常進行故障排除的人來說，這是一個根深蒂固的過程；解釋如何進行故障排除很困難，就像解釋如何騎自行車一樣。然而，我們相信故障排除既是可學習的，也是可教授的。

新手在進行故障排除時常常會遇到困難，因為這項練習理想情況下取決於兩個因素：對如何進行通用故障排除的理解（即，沒有任何特定的系統知識）和對系統的扎實知識。雖然您可以僅使用通用流程和從第一性原理推導來調查問題，58 但我們通常發現這種方法不如理解事物應該如何工作那樣有效率和效果。對系統的了解通常會限制一個新加入系統的 SRE 的效率；學習系統是如何設計和建構的幾乎沒有替代品。

讓我們來看看故障排除過程的一個通用模型。在故障排除方面有專業知識的讀者可能會對我們的定義和過程有所挑剔；如果您的方法對您有效，就沒有理由不堅持使用它。

## 理論

形式上，我們可以將故障排除過程視為**假設演繹法 (hypothetico-deductive method)** 的應用：59 給定一組關於系統的觀察和一個理解系統行為的理論基礎，我們反覆地假設失敗的潛在原因，並試圖測試這些假設。

在一個理想化的模型中，例如圖 12-1 中的模型，我們會從一個告訴我們系統有問題的問題報告開始。然後我們可以查看系統的**遙測 (telemetry)** 60 和日誌來了解其當前狀態。這些資訊，結合我們對系統如何建構、如何運作及其故障模式的了解，使我們能夠識別一些可能的原因。

然後我們可以通過兩種方式來測試我們的假設。我們可以將系統的觀察狀態與我們的理論進行比較，以找到證實或否證的證據。或者，在某些情況下，我們可以主動「處理」系統——也就是說，以受控的方式更改系統並觀察結果。第二種方法可以加深我們對系統狀態和報告問題的可能原因的理解。使用這兩種策略中的任何一種，我們反覆測試，直到確定根本原因，屆時我們就可以採取糾正措施以防止再次發生，並撰寫事後檢討。當然，修復直接原因不一定總是要等到找到根本原因或撰寫事後檢討之後。

無效的故障排除會話會因分類、檢查和診斷步驟中的問題而受到困擾，通常是因為缺乏對系統的深入了解。以下是需要避免的常見陷阱：

- 查看不相關的症狀或誤解系統指標的含義。常常會導致徒勞無功。
- 誤解如何更改系統、其輸入或其環境，以便安全有效地測試假設。
- 提出極不可能的關於問題所在的理論，或固守過去問題的原因，認為既然發生過一次，就一定會再次發生。
- 追查實際上是巧合或與共同原因相關的虛假相關性。

解決第一和第二個常見陷阱需要學習相關系統，並熟悉分散式系統中使用的常見模式。第三個陷阱是一系列邏輯謬誤，可以通過記住並非所有故障都同等可能來避免——正如醫生所教導的，「當你聽到蹄聲時，想想馬而不是斑馬。」61 還要記住，在所有其他條件相同的情況下，我們應該偏好更簡單的解釋。62

最後，我們應該記住，相關性不等於因果關係：63 一些相關的事件，比如說一個叢集內的封包遺失和叢集中的硬碟故障，可能有共同的原因——在這種情況下，是停電，儘管網路故障顯然不會導致硬碟故障，反之亦然。更糟糕的是，隨著系統規模和複雜性的增長以及監控的指標越來越多，不可避免地會有一些事件純粹出於巧合而與其他事件高度相關。64

了解我們推理過程中的失敗是避免它們並更有效地解決問題的第一步。一個有條不紊的方法，知道我們知道什麼、我們不知道什麼以及我們需要知道什麼，可以讓我們更簡單、更直接地找出問題所在以及如何解決它。

# 實踐中

當然，在實踐中，故障排除從來不像我們理想化的模型所建議的那樣乾淨俐落。有一些步驟可以使這個過程對那些遇到系統問題的人和那些回應問題的人來說都不那麼痛苦，並且更有效率。

## 問題報告

每個問題都始於一份問題報告，這可能是一個自動警報，也可能是您的一位同事說：「系統很慢。」一份有效的報告應該告訴您預期的行為、實際的行為，以及如果可能的話，如何重現該行為。65 理想情況下，報告應該有統一的格式，並儲存在一個可搜索的位置，例如錯誤跟踪系統。在這裡，我們的團隊通常有客製化的表單或小型網頁應用程式，詢問與診斷他們支持的特定系統相關的資訊，然後自動生成並路由一個錯誤。這也可能是一個好時機，為問題報告者提供工具，讓他們自己嘗試診斷或修復常見問題。

在 Google，為每個問題都開設一個錯誤報告是常見的做法，即使是通過電子郵件或即時通訊收到的問題。這樣做可以創建一個調查和補救活動的日誌，以便將來參考。許多團隊不鼓勵直接向某個人報告問題，原因有幾個：這種做法引入了一個額外的步驟，即將報告轉錄到錯誤報告中，產生的報告品質較低，團隊其他成員也看不到，並且傾向於將解決問題的負擔集中在報告者碰巧認識的少數團隊成員身上，而不是當前值班的人（另請參閱「處理中斷」）。

> 您正在為莎士比亞搜尋服務值班，並收到一個警報，`Shakespeare-BlackboxProbe_SearchFailure`：您的黑盒監控在過去五分鐘內無法找到「the forms of things unknown」的搜尋結果。警報系統已經提交了一個錯誤，其中包含指向黑盒探測器最近結果的連結以及該警報的應對手冊條目，並將其分配給您。是時候採取行動了！

## 分類 (Triage)

收到問題報告後，下一步是弄清楚該怎麼辦。問題的嚴重程度各不相同：一個問題可能只在非常特定的情況下影響一個用戶（並且可能有解決方法），或者它可能導致一個服務的全球性完全中斷。您的回應應該與問題的影響相稱：對於後者，宣布全員緊急狀態是適當的（請參閱「管理事件」），但對於前者則小題大作。評估一個問題的嚴重性需要運用良好的工程判斷力，並且通常需要在壓力下保持鎮定。

在一次重大中斷中，您的第一反應可能是開始進行故障排除，並試圖盡快找到根本原因。**忽略那種本能！**

相反，您的行動方針應該是**在當前情況下讓系統盡可能地正常工作**。這可能需要採取緊急措施，例如將流量從一個損壞的叢集轉移到仍在工作的其他叢集，完全丟棄流量以防止連鎖故障，或禁用子系統以減輕負載。**止血**應該是您的首要任務；如果您在尋找根本原因時系統崩潰了，那您就沒有在幫助您的用戶。當然，強調快速分類並不妨礙採取措施保存問題所在的證據，例如日誌，以幫助後續的根本原因分析。

新手飛行員被教導，他們在緊急情況下的首要責任是**駕駛飛機** [Gaw09]；故障排除是次要的，首要的是讓飛機和機上所有人都安全著陸。這種方法也適用於計算機系統：例如，如果一個錯誤可能導致無法恢復的資料損壞，凍結系統以防止進一步的故障可能比讓這種行為繼續下去要好。

對於新的 SRE，尤其是那些先前在產品開發組織有經驗的 SRE 來說，這種認識通常相當令人不安且違反直覺。

## 檢查 (Examine)

我們需要能夠檢查系統中的每個組件正在做什麼，以便了解它是否行為正常。

理想情況下，一個監控系統正在為您的系統記錄指標，如「來自時間序列資料的實用警報」中所述。這些指標是找出問題所在的一個很好的起點。繪製時間序列圖和對時間序列進行操作，可以有效地了解系統特定部分的行為，並找到可能暗示問題開始之處的相關性。66

日誌是另一個寶貴的工具。匯出關於每個操作和系統狀態的資訊，可以讓我們確切地了解一個進程在給定時間點正在做什麼。您可能需要分析一個或多個進程的系統日誌。使用像 Dapper [Sig10] 這樣的工具來跟踪請求在整個堆疊中的路徑，提供了一種非常強大的方式來了解一個分散式系統是如何工作的，儘管不同的使用案例意味著截然不同的跟踪設計 [Sam14]。

文本日誌對於即時的反應式除錯非常有幫助，而將日誌儲存在結構化的二進位格式中，則可以建立工具，用更多的資訊進行回顧性分析。

擁有多個詳細級別，以及一種可以隨時提高這些級別的方法，真的很有用。這個功能讓您能夠以令人難以置信的細節檢查任何或所有操作，而無需重新啟動您的進程，同時仍然允許您在服務正常運行時調低詳細級別。根據您的服務收到的流量大小，使用統計採樣可能會更好；例如，您可能每 1000 個操作中顯示一個。

下一步是包含一個選擇語言，這樣您就可以說「顯示匹配 X 的操作」，其中 X 的範圍很廣——例如，負載大小低於 1024 位元組的 `Set` RPC，或返回時間超過 10 毫秒的操作，或在 `rpc_handler.py` 中呼叫了 `doSomethingInteresting()` 的操作。您甚至可能想設計您的日誌基礎設施，以便您可以根據需要快速、選擇性地將其打開。

暴露當前狀態是我們工具箱中的第三個技巧。例如，Google 伺服器有顯示最近發送或接收的 RPC 樣本的端點，因此可以在不參考架構圖的情況下了解任何一台伺服器如何與其他伺服器通信。這些端點還顯示每種類型 RPC 的錯誤率和延遲的直方圖，因此可以快速判斷哪些是不健康的。一些系統有顯示其當前配置或允許檢查其資料的端點；例如，Google 的 Borgmon 伺服器（「來自時間序列資料的實用警報」）可以顯示它們正在使用的監控規則，甚至允許逐步跟踪一個特定的計算到從中得出一個值的源指標。

最後，您甚至可能需要檢測一個客戶端來進行實驗，以便發現一個組件對請求的回應是什麼。

> 使用錯誤報告中指向黑盒監控結果的連結，您發現探測器向 `/api/search` 端點發送了一個 HTTP GET 請求：
> `GET /api/search?query=the+forms+of+things+unknown`
> 它期望收到一個 HTTP 200 回應碼和一個與以下完全匹配的 JSON 負載：
> `{"results": ["A Midsummer Night's Dream"]}`
>
> 系統設定為每分鐘發送一次探測；在過去 10 分鐘內，大約一半的探測成功了，但沒有明顯的模式。不幸的是，探測器沒有顯示失敗時返回了什麼；您記下這一點以便將來修復。
>
> 使用 `curl`，您手動向搜尋端點發送請求，得到一個失敗的回應，HTTP 回應碼為 502（錯誤的網關），並且沒有負載。它有一個 HTTP 標頭，`X-Request-Trace`，其中列出了負責回應該請求的後端伺服器的位址。有了這些資訊，您現在可以檢查那些後端，以測試它們是否回應正常。

## 診斷 (Diagnose)

對系統設計的透徹理解對於提出關於問題所在的合乎情理的假設，無疑是有幫助的，但也有一些通用的實踐，即使沒有領域知識也會有所幫助。

### 簡化和縮減

理想情況下，系統中的組件具有定義明確的介面，並執行從其輸入到其輸出的已知轉換（在我們的例子中，給定一個輸入的搜尋文本，一個組件可能會返回包含可能匹配項的輸出）。然後就有可能查看組件之間的連接，或者等效地，查看它們之間流動的資料，以確定給定的組件是否正常工作。在每一步注入已知的測試資料以檢查結果輸出是否符合預期（一種黑盒測試的形式）可能特別有效，注入旨在探測可能錯誤原因的資料也是如此。擁有一個可靠的可重現的測試案例可以使除錯速度快得多，並且可能可以在非生產環境中使用該案例，在該環境中可以使用比在生產環境中更具侵入性或風險的技術。

**分而治之 (Dividing and conquering)** 是一種非常有用的通用解決方案技術。在一個工作貫穿整個組件堆疊的多層系統中，通常最好從堆疊的一端系統地開始，然後向另一端工作，依次檢查每個組件。這種策略也同樣適用於資料處理管線。在特別大的系統中，線性進行可能太慢；一種替代方案，**二分法 (bisection)**，將系統一分為二，並檢查一側和另一側組件之間的通信路徑。在確定一側似乎工作正常後，重複該過程，直到剩下一個可能有故障的組件。

### 問「什麼」、「哪裡」和「為什麼」

一個出現故障的系統通常仍然在嘗試做**某件事**——只是不是你希望它做的那件事。找出它在做什麼，然後問**為什麼**它要那樣做，以及它的資源用在了**哪裡**，或者它的輸出去了**哪裡**，可以幫助你了解事情是如何出錯的。67

**症狀**：一個 Spanner 叢集延遲很高，對其伺服器的 RPC 超時。

**為什麼**？Spanner 伺服器任務正在使用其所有的 CPU 時間，無法處理客戶端發送的所有請求。

伺服器中的 CPU 時間用在了**哪裡**？對伺服器進行分析顯示，它正在對檢查點到磁碟的日誌中的條目進行排序。

日誌排序程式碼中的 CPU 時間用在了**哪裡**？在對日誌檔案路徑評估正則表達式時。

**解決方案**：重寫正則表達式以避免回溯。在程式碼庫中尋找類似的模式。考慮使用 RE2，它不會回溯並保證運行時隨輸入大小線性增長。68

### 最後動過它的是什麼

系統具有慣性：我們發現，一個正常工作的計算機系統傾向於保持運動狀態，直到受到外力作用，例如配置變更或服務負載類型的轉變。系統最近的變更可能是找出問題所在的富有成效的起點。69

設計良好的系統應該有廣泛的生產日誌，以跟踪從處理用戶流量的伺服器二進位檔案到安裝在叢集中各個節點上的軟體包等所有堆疊層級的新版本部署和配置變更。將系統性能和行為的變化與系統和環境中的其他事件相關聯，也有助於構建監控儀表板；例如，您可以像圖 12-2 中看到的那樣，在一個顯示系統錯誤率的圖表上，用新版本的部署開始和結束時間進行註釋。

> 手動向 `/api/search` 端點發送請求（請參閱「除錯莎士比亞」）並看到失敗訊息列出了處理該回應的後端伺服器，這讓您可以排除問題出在 API 前端伺服器和負載均衡器上的可能性：如果請求至少沒有到達搜尋後端並在那裡失敗，回應可能就不會包含那些資訊。現在您可以將精力集中在後端——分析它們的日誌，發送測試查詢以查看它們返回什麼回應，以及檢查它們匯出的指標。

### 特定診斷

雖然前面描述的通用工具在廣泛的問題領域都很有幫助，但您可能會發現，建立工具和系統來幫助診斷您的特定服務會很有幫助。Google SRE 花費大量時間來建立此類工具。雖然其中許多工具必然是針對特定系統的，但請務必在服務和團隊之間尋找共同點，以避免重複工作。

## 測試和處理

一旦你列出了一個簡短的可能原因列表，就該試圖找出哪個因素是實際問題的根源了。使用實驗方法，我們可以嘗試證實或排除我們的假設。例如，假設我們認為問題是由應用程式邏輯伺服器和資料庫伺服器之間的網路故障，或資料庫拒絕連接引起的。嘗試使用應用程式邏輯伺服器使用的相同憑證連接到資料庫可以反駁第二個假設，而 ping 資料庫伺服器可能能夠反駁第一個假設，這取決於網路拓撲、防火牆規則和其他因素。跟隨程式碼並試圖一步步模仿程式碼流程，可能會準確地指出問題所在。

在設計測試時，需要考慮許多因素（測試可能像發送一個 ping 一樣簡單，也可能像從叢集中移除流量並注入特殊格式的請求以發現競爭條件一樣複雜）：

- 一個理想的測試應該有相互排斥的替代方案，這樣它就可以證實一組假設，同時排除另一組。在實踐中，這可能很難實現。
- **首先考慮最明顯的**：按照可能性的遞減順序執行測試，同時考慮測試對系統可能帶來的風險。在查看最近的配置變更是否移除了用戶對第二台機器的存取權限之前，測試兩台機器之間的網路連接問題可能更有意義。
- 實驗可能會因為**混雜因素 (confounding factors)** 而提供誤導性的結果。例如，防火牆規則可能只允許從特定 IP 位址存取，這可能會導致從您的工作站 ping 資料庫失敗，即使從應用程式邏輯伺服器的機器上 ping 會成功。
- **主動測試可能會產生改變未來測試結果的副作用**。例如，允許一個進程使用更多的 CPU 可能會使操作更快，但可能會增加遇到資料競爭的可能性。同樣，打開詳細日誌可能會使延遲問題變得更糟，並混淆您的結果：問題是自行惡化的，還是因為日誌記錄？
- **有些測試可能不是決定性的，只是提示性的**。要以及時且可重現的方式使競爭條件或死鎖發生可能非常困難，因此您可能不得不滿足於這些是原因的較不確定的證據。

清楚地記錄下你的想法、你運行的測試以及你看到的結果。70 特別是當你處理更複雜、更持久的案例時，這份文件對於幫助你記住到底發生了什麼，以及防止重複這些步驟至關重要。71 如果你通過改變一個系統來進行主動測試——例如，通過給一個進程更多的資源——以系統化和有文件記錄的方式進行更改，將有助於你將系統恢復到測試前的設定，而不是在一個未知的混亂配置中運行。

# 負面結果是神奇的

作者：Randall Bosetti 編輯：Joan Wendt

「負面」結果是指預期效果不存在的實驗結果——也就是說，任何未按計劃進行的實驗。這包括未能改進其所取代的系統的新設計、啟發式方法或人為流程。

不應忽視或低估負面結果。意識到自己錯了有很大的價值：一個明確的負面結果可以解決一些最困難的設計問題。通常一個團隊有兩個看似合理的設計，但一個方向的進展必須解決關於另一個方向是否可能更好的模糊和推測性問題。

具有負面結果的實驗是**結論性的**。它們告訴我們關於生產、設計空間或現有系統性能極限的某些確定的事情。它們可以幫助其他人確定他們自己的實驗或設計是否值得。例如，某個開發團隊可能會決定不使用某個特定的網頁伺服器，因為它在因鎖爭用而失敗之前，只能處理所需 8000 個連接中的約 800 個。當後來的開發團隊決定評估網頁伺服器時，他們可以將這個已經有詳細記錄的負面結果作為起點，快速決定 (a) 他們是否需要少於 800 個連接，或 (b) 鎖爭用問題是否已解決，而不是從頭開始。

即使負面結果不直接適用於其他人的實驗，收集到的補充資料也可以幫助其他人選擇新的實驗或避免先前設計中的陷阱。微基準測試、記錄在案的反模式和專案事後檢討都屬於這一類。在設計實驗時，您應該考慮負面結果的範圍，因為一個廣泛或特別可靠的負面結果將對您的同事更有幫助。

工具和方法可以超越實驗本身，為未來的工作提供資訊。舉個例子，基準測試工具和負載生成器可以同樣容易地從一個證偽的實驗中產生，就像從一個證實的實驗中產生一樣。許多網站管理員都從產生 Apache Bench（一個網頁伺服器負載測試）的困難、注重細節的工作中受益，儘管其最初的結果可能令人失望。

為可重複的實驗建立工具也可能帶來間接的好處：雖然您建立的一個應用程式可能不會從將其資料庫放在 SSD 上或為密集鍵創建索引中受益，但下一個應用程式可能就會。編寫一個允許您輕鬆嘗試這些配置變更的腳本，可以確保您在下一個專案中不會忘記或錯過優化。

發表負面結果可以改善我們行業的數據驅動文化。考慮到負面結果和統計上的不顯著性，可以減少我們指標中的偏見，並為他人提供一個如何成熟地接受不確定性的範例。通過發表一切，你鼓勵其他人也這樣做，整個行業的集體學習速度會快得多。SRE 已經從高品質的事後檢討中學到了這一課，這對生產穩定性產生了巨大的積極影響。

**發表你的結果**。如果你對一個實驗的結果感興趣，很有可能其他人也一樣。當你發表結果時，那些人就不必自己設計和運行類似的實驗了。避免報告負面結果是很誘人且常見的，因為很容易認為實驗「失敗」了。有些實驗注定要失敗，它們往往會被審查發現。更多的實驗只是因為人們錯誤地認為負面結果不是進步而未被報告。

盡你的一份力，告訴大家你已經排除了哪些設計、演算法和團隊工作流程。通過承認負面結果是深思熟慮的風險承擔的一部分，以及每個精心設計的實驗都有其價值，來鼓勵你的同事。對任何沒有提及失敗的設計文件、績效評估或文章持懷疑態度。這樣的文件可能要麼過濾得太嚴重，要麼作者的方法不夠嚴謹。

最重要的是，**發表你覺得驚訝的結果**，這樣其他人——包括未來的你——就不會感到驚訝了。

## 治癒 (Cure)

理想情況下，您現在已經將可能的原因範圍縮小到一個。接下來，我們想證明它就是實際的原因。在生產系統中，通過隨意重現來明確證明某個因素導致了問題，可能很困難；通常，我們只能找到可能的原因因素，原因如下：

- **系統是複雜的**。很可能有多個因素，每個因素單獨都不是原因，但它們共同作用才是原因。72 真實系統也常常是**路徑依賴的 (path-dependent)**，因此它們必須處於一個特定的狀態，故障才會發生。
- **在即時生產系統中重現問題可能不是一個選項**，這要麼是因為讓系統進入可以觸發故障的狀態很複雜，要麼是因為進一步的停機時間是不可接受的。擁有一個非生產環境可以緩解這些挑戰，儘管代價是需要運行另一個系統的副本。

一旦你找到了導致問題的因素，就該寫下關於系統出了什麼問題、你是如何追查到問題的、你是如何解決問題的，以及如何防止它再次發生的筆記了。換句話說，你需要寫一份**事後檢討 (postmortem)**（儘管理想情況下，此時系統還活著！）。

# 案例研究

App Engine，73 作為 Google 雲端平台的一部分，是一個平台即服務 (PaaS) 產品，允許開發人員在 Google 的基礎設施之上建構服務。我們的一個內部客戶提交了一份問題報告，指出他們最近發現其應用程式的延遲、CPU 使用率和服務流量所需的運行進程數量急劇增加，該應用程式是一個用於為開發人員建構文件的內容管理系統。74 客戶找不到任何與資源增加相關的近期程式碼變更，而且其應用程式的流量也沒有增加（見圖 12-3），所以他們想知道是否是 App Engine 服務的變更造成的。

我們的調查發現，延遲確實增加了近一個數量級（如圖 12-4 所示）。同時，CPU 時間（圖 12-5）和服務進程數量（圖 12-6）幾乎翻了兩番。顯然出了問題。是時候開始故障排除了。

通常，延遲和資源使用率的突然增加表明要麼是發送到系統的流量增加，要麼是系統配置的變更。然而，我們可以輕鬆地排除這兩種可能的原因：雖然應用程式在 20:45 左右的流量高峰可以解釋資源使用率的短暫激增，但我們預計在請求量正常化後不久，流量就會回到基線。這種高峰肯定不應該持續數天，從應用程式開發人員提交報告我們開始調查問題時開始。其次，性能的變化發生在周六，當時應用程式和生產環境都沒有進行變更。該服務最近的程式碼推送和配置推送都在幾天前完成了。此外，如果問題源於該服務，我們預計會在使用相同基礎設施的其他應用程式上看到類似的影響。然而，沒有其他應用程式出現類似的影響。

我們將問題報告轉給了我們的對口部門，即 App Engine 的開發人員，以調查客戶是否遇到了服務基礎設施中的任何特殊情況。開發人員也未能發現任何異常。然而，一位開發人員注意到延遲增加與一個特定的資料儲存 API 呼叫 `merge_join` 的增加之間存在相關性，這通常表示從資料儲存中讀取時索引不佳。在應用程式用於從資料儲存中選擇物件的屬性上添加一個複合索引會加快這些請求的速度，原則上，也會加快整個應用程式的速度——但我們需要弄清楚哪些屬性需要索引。快速查看應用程式的程式碼並沒有發現任何明顯的嫌疑。

是時候拿出我們工具箱裡的重型機械了：使用 Dapper [Sig10]，我們跟踪了單個 HTTP 請求從被前端反向代理接收到應用程式程式碼返回回應的各個步驟，並查看了處理該請求所涉及的每個伺服器發出的 RPC。這樣做可以讓我們看到哪些屬性包含在對資料儲存的請求中，然後創建適當的索引。

在調查過程中，我們發現對靜態內容（如圖片）的請求（這些內容不是從資料儲存中提供的）也比預期的要慢得多。查看具有檔案級別粒度的圖表，我們看到它們的回應在幾天前要快得多。這意味著觀察到的 `merge_join` 和延遲增加之間的相關性是虛假的，我們的次優索引理論是致命的錯誤。

檢查意外緩慢的靜態內容請求，從應用程式發出的大部分 RPC 都發往了一個 memcache 服務，因此請求應該非常快——在幾毫秒的數量級。這些請求確實非常快，所以問題似乎並非源於此。然而，在應用程式開始處理請求和它發出第一個 RPC 之間，大約有 250 毫秒的時間，應用程式在做……嗯，**某件事**。因為 App Engine 運行的是用戶提供的程式碼，其 SRE 團隊不會分析或檢查應用程式程式碼，所以我們無法判斷應用程式在那個間隔內在做什麼；同樣，Dapper 也無法幫助追踪發生了什麼，因為它只能追踪 RPC 呼叫，而在那個時期內沒有發出任何 RPC 呼叫。

面對這個到此為止相當神秘的問題，我們決定**暫時**不解決它。客戶計劃在下周進行公開發布，我們不確定多久才能確定問題並解決它。相反，我們建議客戶將分配給其應用程式的資源增加到可用的 CPU 最豐富的實例類型。這樣做將應用程式的延遲降低到了可接受的水平，儘管不如我們期望的那麼低。我們得出結論，延遲的緩解足以讓團隊成功地進行他們的發布，然後再從容地進行調查。75

此時，我們懷疑該應用程式是另一個導致延遲和資源使用突然增加的常見原因的受害者：**工作類型的改變**。我們看到，在延遲增加之前，從該應用程式寫入資料儲存的次數有所增加，但由於這個增加不是很大，也不是持續的，我們就把它當作巧合了。然而，這種行為確實類似於一種常見的模式：應用程式的一個實例通過從資料儲存中讀取物件來初始化，然後將它們儲存在實例的記憶體中。通過這樣做，實例避免了在每個請求上從資料儲存中讀取很少改變的配置，而是檢查記憶體中的物件。然後，處理請求所需的時間通常會隨著配置資料的數量而擴展。76 我們無法證明這種行為是問題的根本原因，但這是一個常見的反模式。

應用程式開發人員增加了儀器檢測，以了解應用程式將時間花在了哪裡。他們識別出一個在每個請求上都會被呼叫的方法，該方法檢查一個用戶是否被列入白名單以存取給定的路徑。該方法使用了一個快取層，該層試圖通過將白名單物件保留在實例的記憶體中，來最小化對資料儲存和 memcache 服務的存取。正如應用程式的一位開發人員在調查中指出的那樣，「我還不知道火在哪裡，但我被這個白名單快取冒出的煙搞得眼花繚亂。」

一段時間後，根本原因被找到了：由於應用程式存取控制系統中一個長期存在的錯誤，每當存取一個特定的路徑時，就會創建一個白名單物件並儲存在資料儲存中。在發布前夕，一個自動化的安全掃描器一直在測試應用程式的漏洞，作為副作用，它的掃描在半小時內產生了數千個白名單物件。然後，這些多餘的白名單物件必須在對應用程式的每個請求上進行檢查，這導致了病態的緩慢回應，而沒有導致應用程式對其他服務的任何 RPC 呼叫。修復該錯誤並移除那些物件後，應用程式的性能恢復到了預期水平。

# 讓故障排除更容易

有很多方法可以簡化和加速故障排除。也許最基本的是：

- 從一開始就為每個組件內建具有白盒指標和結構化日誌的可觀察性
- 設計具有易於理解和可觀察的組件間介面的系統。

確保資訊在整個系統中以一致的方式可用——例如，在各種組件生成的 RPC 範圍內使用唯一的請求識別碼——可以減少弄清楚上游組件上的哪個日誌條目與下游組件上的日誌條目匹配的需要，從而加快診斷和恢復的時間。

在程式碼變更或環境變更中正確表示現實狀態的問題，常常導致需要進行故障排除。簡化、控制和記錄此類變更可以減少故障排除的需求，並在發生時使其更容易。

# 結論

我們已經看了一些可以採取的步驟，使故障排除過程對新手來說清晰易懂，以便他們也能有效地解決問題。採用系統化的故障排除方法——而不是依賴運氣或經驗——可以幫助限制您的服務的恢復時間，從而為您的用戶帶來更好的體驗。

58 事實上，僅使用第一性原理和故障排除技能通常是學習一個系統如何工作的有效方法；請參閱「加速 SRE 的值班與後續發展」。

59 請參閱 https://en.wikipedia.org/wiki/Hypothetico-deductive_model。

60 例如，「來自時間序列資料的實用警報」中描述的匯出變數。

61 歸功於 20 世紀 40 年代馬里蘭大學醫學院的 Theodore Woodward。請參閱 https://en.wikipedia.org/wiki/Zebra_(medicine)。這在某些領域有效，但在某些系統中，整類的故障可能可以被消除：例如，使用一個設計良好的叢集檔案系統意味著延遲問題不太可能是由於單個死磁碟造成的。

62 奧卡姆剃刀；請參閱 https://en.wikipedia.org/wiki/Occam%27s_razor。但請記住，可能仍然存在多個問題；特別是，一個系統可能更有可能有一些常見的低級問題，這些問題綜合起來可以解釋所有症狀，而不是一個單一的罕見問題導致了所有症狀。參見 https://en.wikipedia.org/wiki/Hickam%27s_dictum。

63 當然，請參閱 https://xkcd.com/552。

64 至少，我們沒有合理的理論來解釋為什麼在 2000 年至 2009 年間，美國計算機科學博士學位的授予數量與人均起司消費量之間存在極高的相關性（r2 = 0.9416）：https://tylervigen.com/view_correlation?id=1099。

65 向潛在的錯誤報告者推薦 [Tat99] 可能有助於他們提供高品質的問題報告。

66 但要警惕可能將您引向錯誤道路的虛假相關性！

67 在許多方面，這類似於豐田英二引入的「五個為什麼」技術 [Ohn88]，用於理解製造錯誤的根本原因。

68 與 RE2 相比，PCRE 可能需要指數時間來評估一些正則表達式。RE2 可在 https://github.com/google/re2 獲取。

69 [All15] 觀察到這是在解決中斷時經常使用的啟發式方法。

70 使用共享文件或即時聊天來做筆記，可以提供您做某事的時間戳，這對事後檢討很有幫助。它還與他人共享該資訊，以便他們了解世界的當前狀態，而不必打斷您的故障排除。

71 關於這一點，另請參閱「負面結果是神奇的」。

72 關於如何思考系統，請參閱 [Mea08]，以及關於尋找單一根本原因而不是檢查系統及其環境中的致病因素的局限性，請參閱 [Coo00] 和 [Dek14]。

73 請參閱 https://cloud.google.com/appengine。

74 為了便於理解，我們對這個案例研究進行了壓縮和簡化。

75 雖然帶著一個未識別的錯誤進行發布並不理想，但消除所有已知的錯誤通常是不切實際的。相反，有時我們不得不採取次優措施，並盡我們所能，運用良好的工程判斷力來降低風險。

76 資料儲存查找可以使用索引來加快比較速度，但一個常見的記憶體中實現是在所有快取物件上進行簡單的 for 迴圈比較。如果只有幾個物件，這不會有什麼問題，因為這只需要線性時間——但隨著快取物件數量的增長，這可能會導致延遲和資源使用率的顯著增加。
