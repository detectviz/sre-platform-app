# 附錄 B - 生產服務的最佳實踐集合

作者：Ben Treynor Sloss
編輯：Betsy Beyer

## 理性地失敗 (Fail Sanely)

對設定檔的輸入進行清理和驗證，並在收到不合理的輸入時，透過繼續使用先前的狀態運作並發出警報來回應。不良輸入通常屬於以下幾類：

以一種保留功能的方式失敗，即使這可能意味著過於寬鬆或過於簡化。我們發現，系統繼續使用先前的設定檔運作，並等待人工批准後再使用新的、可能無效的數據，通常更安全。

在 2005 年，由於檔案權限問題，Google 的全球 DNS 負載和延遲平衡系統收到了一個空的 DNS 項目檔案。它接受了這個空檔案，並在六分鐘內對所有 Google 資產回傳了 NXDOMAIN。作為回應，該系統現在會對新的設定檔執行多項健全性檢查，包括確認 google.com 的虛擬 IP 是否存在，並將繼續使用先前的 DNS 項目，直到收到通過其輸入檢查的新檔案為止。

在 2009 年，不正確（但有效）的數據導致 Google 將整個網路標記為含有惡意軟體 [May09]。一個包含可疑 URL 列表的設定檔被單一的斜線字元 (/) 取代，這匹配了所有 URL。如果當時有檢查檔案大小的巨大變化，以及檢查設定檔是否匹配了那些被認為不太可能包含惡意軟體的網站，就可以防止這個問題進入生產環境。

# 漸進式部署 (Progressive Rollouts)

非緊急的部署必須分階段進行。設定檔和二進位檔案的變更都會引入風險，您可以透過一次只將變更應用於小部分的流量和容量來降低這種風險。您的服務或部署的規模，以及您的風險狀況，將決定部署推送到的生產容量百分比，以及各階段之間的適當時間間隔。為了偵測與日夜流量週期和地理流量組合差異相關的問題，在不同地理位置執行不同階段也是一個好主意。

部署應該受到監督。為確保在部署過程中沒有發生意外情況，必須由執行部署階段的工程師，或最好是一個被證明可靠的監控系統來進行監控。如果偵測到意外行為，應先回滾，之後再進行診斷，以最小化平均修復時間 (MTTR)。

# 像使用者一樣定義 SLO (Define SLOs Like a User)

以對終端使用者有意義的術語來衡量可用性和效能。更多討論請參見「服務水準目標」。

在 Gmail 客戶端而不是在伺服器端衡量錯誤率和延遲，導致我們對 Gmail 可用性的評估大幅降低，並促使我們對 Gmail 客戶端和伺服器端的程式碼都進行了更改。結果是，Gmail 在幾年內從大約 99.0% 的可用性提升到超過 99.9% 的可用性。

# 錯誤預算 (Error Budgets)

透過錯誤預算（參見「錯誤預算的動機」）來平衡可靠性與創新步伐，錯誤預算定義了服務在某段時間內可接受的失敗水準；我們通常使用一個月。預算就是 1 減去服務的 SLO；例如，一個可用性目標為 99.99% 的服務，其「不可用」的預算為 0.01%。只要服務在一個月內沒有因為背景錯誤率加上任何停機時間而用完其錯誤預算，開發團隊就可以（在合理範圍內）自由地發布新功能、更新等等。

如果錯誤預算用完了，服務將凍結變更（除了緊急的安全修復和解決導致錯誤增加原因的錯誤修復），直到服務重新贏得預算空間，或月份重置為止。對於 SLO 高於 99.99% 的成熟服務，每季重置預算比每月重置更合適，因為允許的停機時間非常少。

錯誤預算消除了 SRE 和產品開發團隊之間可能產生的結構性緊張關係，因為它為他們提供了一個共同的、數據驅動的機制來評估發布風險。它們還為 SRE 和產品開發團隊提供了一個共同的目標，即開發實踐和技術，以便在不「超出預算」的情況下實現更快的創新和更多的發布。

# 監控 (Monitoring)

監控可能只有三種類型的輸出：

- **警報 (Alerts)**：需要人類立即採取行動。
- **工單 (Tickets)**：需要人類採取行動，但不是立即性的。
- **日誌 (Logging)**：供人類事後查閱的資訊（如果需要）。

如果一件事情重要到需要打擾人類，它要麼需要立即採取行動（即，呼叫），要麼應該被視為一個錯誤並輸入到您的錯誤追蹤系統中。將警報放入電子郵件中，並希望有人會閱讀所有郵件並注意到重要的那封，這在道德上等同於將它們導向 /dev/null：它們最終會被忽略。歷史證明這種策略是一個誘人的麻煩，因為它可能在一段時間內有效，但它依賴於人類永恆的警惕，因此當不可避免的中斷發生時，會更加嚴重。

# 事後檢討 (Postmortems)

事後檢討（參見「事後檢討文化：從失敗中學習」）應該是無指責的，並專注於流程和技術，而不是人。假設參與事件的人是聰明的、意圖良好的，並且在當時可用的資訊下做出了他們能做的最佳選擇。因此，我們不能「修復」人，而必須修復他們的環境：例如，改進系統設計以避免整類問題，使適當的資訊易於獲取，並自動驗證操作決策，使其難以將系統置於危險狀態。

# 容量規劃 (Capacity Planning)

進行資源配置以應對一次計劃性和一次非計劃性的同時中斷，而不使用戶體驗變得不可接受；這導致了「N + 2」的配置，其中峰值流量可以由 N 個實例處理（可能在降級模式下），而最大的 2 個實例不可用：

- **一個用於計劃性下線**：例如，軟體升級。
- **一個用於非計劃性中斷**：例如，硬體故障。

將先前的需求預測與現實進行驗證，直到它們持續匹配。分歧意味著不穩定的預測、低效的資源配置以及容量不足的風險。使用負載測試而不是傳統來確定資源與容量的比率：一個由 X 台機器組成的叢集三個月前可以處理每秒 Y 次查詢，但考慮到系統的變化，它現在還能做到嗎？不要把第一天的負載誤認為是穩定狀態的負載。發布時通常會吸引更多流量，而這也正是您特別希望產品展現最佳一面的時候。參見「大規模可靠的產品發布」和「發布協調檢查清單」。

*   將先前的需求預測與現實進行驗證，直到它們持續匹配。分歧意味著不穩定的預測、低效的資源配置以及容量不足的風險。
*   使用負載測試而不是傳統來確定資源與容量的比率：一個由 X 台機器組成的叢集三個月前可以處理每秒 Y 次查詢，但考慮到系統的變化，它現在還能做到嗎？
*   不要把第一天的負載誤認為是穩定狀態的負載。發布時通常會吸引更多流量，而這也正是您特別希望產品展現最佳一面的時候。參見「大規模可靠的產品發布」和「發布協調檢查清單」。

# 過載與失敗 (Overloads and Failure)

如果服務過載，應產生合理但次優的結果。例如，Google 搜尋在過載時會搜尋索引的一小部分，並停止提供像即時搜尋這樣的功能，以繼續提供高品質的網頁搜尋結果。搜尋 SRE 會對網頁搜尋叢集進行超出其額定容量的測試，以確保它們在流量過載時能可接受地執行。

當負載高到即使是降級的回應對於所有查詢來說也過於昂貴時，應實行優雅的減載，使用行為良好的佇列和動態超時；參見「處理過載」。其他技術包括在顯著延遲後回答請求（「tarpitting」）和選擇一個一致的客戶端子集來接收錯誤，為其餘的客戶端保留良好的用戶體驗。

重試會將低錯誤率放大為更高層級的流量，導致級聯故障（參見「處理級聯故障」）。一旦總負載超過總容量，應透過在系統上游丟棄一部分流量（包括重試！）來應對級聯故障。

每個進行 RPC 的客戶端都必須為重試實現指數退避（帶有抖動），以抑制錯誤放大。行動客戶端尤其麻煩，因為可能有數百萬個，並且更新它們的程式碼以修復行為需要大量時間——可能需要數週——並且需要用戶安裝更新。

# SRE 團隊 (SRE Teams)

SRE 團隊花在運營工作上的時間不應超過 50%（參見「消除瑣事」）；運營工作的溢出部分應導向產品開發團隊。許多服務也將產品開發人員納入 on-call 輪值和工單處理中，即使目前沒有溢出。這提供了設計系統以最小化或消除運營瑣事的誘因，同時確保產品開發人員接觸到服務的運營方面。SRE 和開發團隊之間的定期生產會議（參見「SRE 中的溝通與協作」）也很有幫助。

我們發現，on-call 團隊至少需要八個人，以避免疲勞並實現可持續的人員配置和低流動率。最好，on-call 人員應位於兩個地理位置相距甚遠的地方（例如，加利福尼亞和愛爾蘭），以避免夜間呼叫，從而提供更好的生活品質；在這種情況下，每個站點六個人是最小的團隊規模。

預計每個 on-call 班次（例如，每 12 小時）處理不超過兩個事件：回應和修復中斷、開始事後檢討以及提交由此產生的錯誤都需要時間。更頻繁的事件可能會降低回應品質，並表明系統的設計、監控靈敏度和對事後檢討錯誤的回應中（至少有一個）存在問題。

諷刺的是，如果您實施了這些最佳實踐，SRE 團隊最終可能會因為事件不頻繁而變得不擅長回應事件，從而將一個短暫的中斷變成一個長時間的中斷。應定期練習處理假設的中斷（參見「災難角色扮演」），並在此過程中改進您的事件處理文件。
